{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e26adeff",
   "metadata": {
    "id": "e26adeff"
   },
   "source": [
    "# Neural Network Training Code from Scratch\n",
    "In this tutorial, you will discover how to implement the backpropagation algorithm for a neural network from scratch with Python. After completing this tutorial, you will know:\n",
    "- How to forward-propagate an input to calculate an output.\n",
    "- How to back-propagate error and train a network.\n",
    "- How to apply the backpropagation algorithm to a real-world predictive modeling problem.\n",
    "\n",
    "____"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25ef18b4",
   "metadata": {
    "id": "25ef18b4"
   },
   "source": [
    "# Understanding the Dataset\n",
    "\n",
    "We are using the 'accelerometer.csv' file as the dataset for creating our Artificial Neural Network. This dataset was generated for predicting motor failure modes for different weight configurations using ANNs. \n",
    "\n",
    "There are 5 attributes present in the dataset as follows - \n",
    "\n",
    "1. x : Acceleration in x direction\n",
    "2. y : Acceleration in y direction\n",
    "3. z : Acceleration in z direction\n",
    "4. RPM : \n",
    "5. Weight configuration : Has values of 1, 2 and 3 to denote three different configurations that cause motor failure\n",
    "\n",
    "We wish to use Neural Networks to classify data into these three failure mode configurations. Thus, we are working on a __classification problem__ with our classes being present in the __Weight Configuration__ column"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df8c6953",
   "metadata": {},
   "source": [
    "## Importing the libraries and dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "23b1ac79",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "23b1ac79",
    "outputId": "8df18e6c-49c9-423d-b9dd-f8b4d08dfe21"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>z</th>\n",
       "      <th>RPM</th>\n",
       "      <th>Weight Config</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.004</td>\n",
       "      <td>0.090</td>\n",
       "      <td>-0.125</td>\n",
       "      <td>20</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.004</td>\n",
       "      <td>-0.043</td>\n",
       "      <td>-0.125</td>\n",
       "      <td>20</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.969</td>\n",
       "      <td>0.090</td>\n",
       "      <td>-0.121</td>\n",
       "      <td>20</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.973</td>\n",
       "      <td>-0.012</td>\n",
       "      <td>-0.137</td>\n",
       "      <td>20</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.000</td>\n",
       "      <td>-0.016</td>\n",
       "      <td>-0.121</td>\n",
       "      <td>20</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       x      y      z  RPM  Weight Config\n",
       "0  1.004  0.090 -0.125   20              1\n",
       "1  1.004 -0.043 -0.125   20              1\n",
       "2  0.969  0.090 -0.121   20              1\n",
       "3  0.973 -0.012 -0.137   20              1\n",
       "4  1.000 -0.016 -0.121   20              1"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"accelerometer.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "d565dc90",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(153000, 5)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "ae761058",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 2, 3], dtype=int64)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Classes in our target variable\n",
    "df['Weight Config'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ced43eb6",
   "metadata": {
    "id": "ced43eb6"
   },
   "source": [
    "The range of values for the columns in our dataset are different. Thus It is generally a good practice to normalize input values to the range of the chosen activation function. In this case, the activation function used is sigmoid function that outputs values between 0 and 1. In the wheat seed dataset, the input values vary in scale and hence need to be normalized to the range of 0 and 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "700973d5",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "700973d5",
    "outputId": "3b04196e-5ce8-4ffb-b2a4-941db92cd06a"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>z</th>\n",
       "      <th>RPM</th>\n",
       "      <th>Weight Config</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.562891</td>\n",
       "      <td>0.505751</td>\n",
       "      <td>0.480381</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.562891</td>\n",
       "      <td>0.497437</td>\n",
       "      <td>0.480381</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.560703</td>\n",
       "      <td>0.505751</td>\n",
       "      <td>0.480716</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.560953</td>\n",
       "      <td>0.499375</td>\n",
       "      <td>0.479378</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.562641</td>\n",
       "      <td>0.499125</td>\n",
       "      <td>0.480716</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          x         y         z  RPM  Weight Config\n",
       "0  0.562891  0.505751  0.480381  0.0            0.0\n",
       "1  0.562891  0.497437  0.480381  0.0            0.0\n",
       "2  0.560703  0.505751  0.480716  0.0            0.0\n",
       "3  0.560953  0.499375  0.479378  0.0            0.0\n",
       "4  0.562641  0.499125  0.480716  0.0            0.0"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "normalized_df=(df-df.min())/(df.max()-df.min())\n",
    "normalized_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bb8a3db",
   "metadata": {
    "id": "1bb8a3db"
   },
   "source": [
    "We present the whole process through 4 steps :\n",
    "1. Building the NN\n",
    "2. Forward Propagation\n",
    "3. Calculating Error\n",
    "4. Backpropagation\n",
    "\n",
    "# 1. Building the Neural Network\n",
    "A neural network is organized into layers. The input layer is really just a row from our training dataset. The first real layer is the hidden layer. This is followed by the output layer that has one neuron for each class value.\n",
    "\n",
    "\n",
    "## Number of neurons, weights and biases\n",
    "First task in building the NN is to Calculate the number of input neurons. Number of input neurons is equal to the number of input variables (4 in this case). But, everytime the number of input variables may not be provided. Then, we have to extract it from the dataset. The number of input variables will be 1 less than the number of columns (as the final column represents the class variable). Hence, just slice a row from the dataset, calculate its length and subtract 1 from it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "438cb2bd",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "438cb2bd",
    "outputId": "14d4d477-5ad0-42fc-a991-0694a77cd76b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Number of input neurons\n",
    "n_input = len(normalized_df.iloc[0])-1\n",
    "n_input"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7de31eaf",
   "metadata": {
    "id": "7de31eaf"
   },
   "source": [
    "Next, we fix the number of hidden neurons in the hidden layer (5 in this case)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "b0a23032",
   "metadata": {
    "id": "b0a23032"
   },
   "outputs": [],
   "source": [
    "# Number of hidden neurons\n",
    "n_hidden = 5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eacf086f",
   "metadata": {
    "id": "eacf086f"
   },
   "source": [
    "Then, we fix the number of neurons in the output layer. Number of neurons in the output layer is equal to the number of unique values the class variable can take (3 in this case)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "cd69bd11",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cd69bd11",
    "outputId": "d84d0b4d-6f19-4385-c106-c80c98232249"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_output = len(pd.unique(normalized_df['Weight Config']))\n",
    "n_output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9cf0da2",
   "metadata": {
    "id": "a9cf0da2"
   },
   "source": [
    "You can see that each neuron in the hidden layer has $n_{inputs} + 1$ weights, one for each input column in a dataset and an additional one for the bias. \n",
    "\n",
    "> So the total number of weights from input layer to hidden layer is $n_{hidden} (n_{inputs} + 1)$.\n",
    "\n",
    "You can also see that each neuron in the output layer has $n_{hidden} + 1$ weights. This means that each neuron in the output layer connects to each neuron in the hidden layer and an additional one for the bias. \n",
    "\n",
    "> So the total number of weights from hidden layer to output layer is $n_{output} . (n_{hidden} + 1)$.\n",
    "\n",
    "> Hence, total number of weights to be optimized in the NN is $n_{hidden} (n_{inputs} + 1) + n_{output}(n_{hidden} + 1)$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "00c1681f",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "00c1681f",
    "outputId": "c256b924-ca54-44bf-ad91-7f9243525ad4"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Number of weights from input layer to hidden layer \n",
    "# input_to_hidden = n_hidden X (n_inputs + 1) = 5 X (4 + 1) = 25\n",
    "input_to_hidden = n_hidden * (n_input + 1)\n",
    "input_to_hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "22222b99",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "22222b99",
    "outputId": "504d1e69-b240-47a0-a147-d4f119185df4"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Number of weights from hidden layer to output layer\n",
    "# hidden_to_output = n_output X (n_hidden + 1) = 3 X (5 + 1) = 18\n",
    "hidden_to_output = n_output * (n_hidden + 1)\n",
    "hidden_to_output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af017852",
   "metadata": {
    "id": "af017852"
   },
   "source": [
    "## Initialize weights\n",
    "It is a good practice to initialize the network weights to small random numbers. In this case, we will use random numbers in the range of 0 to 1. We will organize layers as arrays and treat the whole network as an array of layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0be5cb81",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0be5cb81",
    "outputId": "c294d96a-1e79-400d-fb76-7eef2b2b6224"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.31974432, 0.73800723, 0.45648306, 0.47700643, 0.85120776],\n",
       "       [0.74391344, 0.75210287, 0.70634862, 0.46570561, 0.99918339],\n",
       "       [0.28754272, 0.76581885, 0.60277315, 0.99570128, 0.48114054],\n",
       "       [0.87224625, 0.62791782, 0.32445119, 0.89508715, 0.99971592],\n",
       "       [0.98211976, 0.66816178, 0.27921971, 0.06291457, 0.1748827 ]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from random import random\n",
    "network = list()\n",
    "\n",
    "hidden_layer_weights = np.zeros((5,5))\n",
    "for i in range(n_hidden):\n",
    "    for j in range(n_input + 1):\n",
    "        hidden_layer_weights[i,j] = random()\n",
    "    \n",
    "#hidden_layer_weights = np.asarray([[random() for i in range(n_input + 1)] for i in range(n_hidden)])\n",
    "network.append(hidden_layer_weights)\n",
    "\n",
    "# Weights of first neuron in hidden layer\n",
    "hidden_layer_weights[0]\n",
    "\n",
    "hidden_layer_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5c8cc3a4",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5c8cc3a4",
    "outputId": "cf29165d-0940-439c-fa4a-17aebc1fd4c6",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.13324626, 0.06745881, 0.43720079, 0.1484701 , 0.80803343,\n",
       "        0.81128958],\n",
       "       [0.89124622, 0.90273149, 0.21516128, 0.2620276 , 0.68384807,\n",
       "        0.69312608],\n",
       "       [0.33467901, 0.11002255, 0.78066162, 0.4371893 , 0.66543744,\n",
       "        0.61890627]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_layer_weights = np.asarray([[random() for i in range(n_hidden + 1)] for i in range(n_output)])\n",
    "network.append(output_layer_weights)\n",
    "\n",
    "# Weights of first neuron in output layer\n",
    "output_layer_weights[0]\n",
    "\n",
    "output_layer_weights"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3faf9ea",
   "metadata": {
    "id": "d3faf9ea"
   },
   "source": [
    "# Visualizing the NN\n",
    "\n",
    "![alternatvie text](https://static.javatpoint.com/tutorial/artificial-neural-network/images/artificial-neural-network6.png)\n",
    "\n",
    "Now that we know how to create and initialize a network, let’s see how we can use it to calculate an output.\n",
    "\n",
    "## 2. Forward Propagation\n",
    "We can calculate an output from a neural network by propagating an input signal through each layer until the output layer outputs its values. We call this forward-propagation.\n",
    "\n",
    "It is the technique we will need to generate predictions during training that will need to be corrected, and it is the method we will need after the network is trained to make predictions on new data.\n",
    "\n",
    "We can break forward propagation down into 2 parts:\n",
    "1. Calculate net input to a neuron\n",
    "2. Apply activation function\n",
    "\n",
    "### Calculate net input to a neuron\n",
    "In case of hidden layer, the net input to each neuron is calculated from the input data and the weights corresponding to that hidden neuron from input layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "817f22d7",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "817f22d7",
    "outputId": "a6666859-bdd3-4a9d-d898-967a1f435c65"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "x      0.562891\n",
       "y      0.505751\n",
       "z      0.480381\n",
       "RPM    0.000000\n",
       "Name: 0, dtype: float64"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sample input data\n",
    "# Take the first row of normalized data without the class label\n",
    "sample_input = normalized_df.iloc[0, 0:4]\n",
    "sample_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "63de619f",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "63de619f",
    "outputId": "e648a669-12bc-4489-9758-5ac5c9221e41"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.56289072, 0.50575144, 0.48038149, 0.        , 1.        ])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Append '1' to sample input for bias\n",
    "sample_input = np.append(sample_input,[1])\n",
    "sample_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "9ee761cd",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9ee761cd",
    "outputId": "23030ce4-049c-4181-914d-430a19f36d79"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([9.54047484, 9.70029883, 9.70958548, 9.68368282, 9.57015089])"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculate net input to each hidden neuron\n",
    "hidden_net_input = list()\n",
    "for layer in hidden_layer_weights:\n",
    "    hidden_net_input.append(sum(layer*sample_input))\n",
    "hidden_net_input = np.asarray(hidden_net_input)\n",
    "hidden_net_input"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e86de89",
   "metadata": {
    "id": "4e86de89"
   },
   "source": [
    "### Apply activation function\n",
    "Once the net input to a neuron is calculated, we need to pass that through the activation function of that neuron to get the output of the neuron. Here, we use the sigmoid activation function for all the layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hzZF5_1VLJzq",
   "metadata": {
    "id": "hzZF5_1VLJzq"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "2096cafc",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2096cafc",
    "outputId": "e9a9a3a9-0586-41a1-b8b7-54a0ed956058"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.99992812, 0.99993874, 0.9999393 , 0.99993771, 0.99993022])"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import math\n",
    "hidden_layer_output = list()\n",
    "hidden_net_input = [i*(-1) for i in hidden_net_input]\n",
    "for each_net_input in hidden_net_input:\n",
    "    hidden_layer_output.append(1 / (1 + math.exp(each_net_input)))\n",
    "hidden_layer_output = np.asarray(hidden_layer_output)\n",
    "hidden_layer_output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93e6b4d5",
   "metadata": {
    "id": "93e6b4d5"
   },
   "source": [
    "We work through each layer of our network calculating the outputs for each neuron. All of the outputs from one layer become inputs to the neurons on the next layer. The outputs of the hidden layer calculated above **hidden_layer_output** is used as inputs to the output layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "376c53df",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "376c53df",
    "outputId": "46bb55e6-cb0d-41e4-d11b-e1f95a013e48"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.70509611, -1.21404339, -0.7707452 ])"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Append '1' to input for bias\n",
    "output_layer_input = np.append(hidden_layer_output,[1])\n",
    "output_layer_input\n",
    "\n",
    "# Calculate net input to each output neuron\n",
    "output_net_input = list()\n",
    "for layer in output_layer_weights:\n",
    "    output_net_input.append(sum(layer*output_layer_input))\n",
    "output_net_input = np.asarray(output_net_input)\n",
    "output_net_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "0649983f",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0649983f",
    "outputId": "6a336217-4eb0-4c77-f297-4a8ce99aa8bc"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.33068332, 0.2289864 , 0.31631793])"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Apply activation function\n",
    "output_layer_output = list()\n",
    "output_net_input = [i*(-1) for i in output_net_input]\n",
    "for each_net_input in output_net_input:\n",
    "    output_layer_output.append(1 / (1 + math.exp(each_net_input)))\n",
    "output_layer_output = np.asarray(output_layer_output)\n",
    "output_layer_output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f069bf5",
   "metadata": {
    "id": "3f069bf5"
   },
   "source": [
    "## 3. Calculating Error\n",
    "Convert the class label into binary patterns. There are 3 classes in this problem i.e. 3 types of seeds. These can be converted to their corresponding binary patterns :\n",
    "- 1 --> [1,0,0]\n",
    "- 2 --> [0,1,0]\n",
    "- 3 --> [0,0,1]\n",
    "\n",
    "The output layer has 3 neurons which output 3 values. These are stored in **output_layer_output**. Now, these values will be compared to the corresponding binary patterns to find the error/loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "8de2ab9b",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8de2ab9b",
    "outputId": "f6c50458-f871-4446-97e1-8ea005128f52"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Class label corresponding to sample_input\n",
    "class_label = df.iloc[0,4]\n",
    "class_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "e3a46317",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "e3a46317",
    "outputId": "35c8caf0-6c68-4cb4-a746-90f9c3ddfb67"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 0])"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sample_output corresponding to class_label\n",
    "if class_label == 1:\n",
    "    sample_output = np.asarray([1,0,0])\n",
    "elif class_label == 2:\n",
    "    sample_output = np.asarray([0,1,0])\n",
    "else:\n",
    "    sample_output = np.asarray([0,0,1])\n",
    "sample_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "26a1ad24",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "26a1ad24",
    "outputId": "e06c0649-c669-460c-f1a7-66177faf1528"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3002383072806153"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculate error\n",
    "\n",
    "# Difference between ideal output and actual output\n",
    "diff = output_layer_output - sample_output\n",
    "\n",
    "# Square of the difference\n",
    "sqr = diff**2\n",
    "\n",
    "# Error\n",
    "error = sum(0.5*sqr)\n",
    "error"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0abbe2a9",
   "metadata": {
    "id": "0abbe2a9"
   },
   "source": [
    "## 4. Backpropagation\n",
    "\n",
    "### Calculating Gradient (Output Layer)\n",
    "\n",
    "Now, we have to calculate how much this error changes with the change of each weight from hidden layer to output layer i.e. weights stored in **output_layer_weights**.\n",
    "\n",
    "*[We are not showing the derivations of the following equations. These can be found in the slides]*\n",
    "\n",
    "$\\frac{\\delta{E_{total}}}{\\delta{w_{h1o1}}}={\\delta_{o1}}*input_{h1o1}$\n",
    "\n",
    "$\\frac{\\delta{E_{total}}}{\\delta{w_{h1o1}}}=-(expected_{o1}-actual_{o1})*actual_{o1}(1-actual_{o1})*input_{h1o1}$\n",
    "\n",
    "where, ${w_{h1o1}}$ is the weight of the connection between hidden neuron ${h_1}$ and output neuron ${o_1}$, ${expected_{o1}}$ is the ideal output from neuron ${o_1}$, ${actual_{o1}}$ is the calculated output from neuron ${o_1}$ and ${input_{h1o1}}$ is the input from neuron ${h_1}$ to ${o_1}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "94c084ae",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "94c084ae",
    "outputId": "50dbc3c4-64d6-48b9-d8c6-68777324595f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.14813045897327515"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "expected = sample_output[0]\n",
    "actual = output_layer_output[0]\n",
    "input_h1_to_o1 = hidden_layer_output[0]\n",
    "delta_o1 = -(expected-actual)*actual*(1-actual)\n",
    "gradient_h1_to_o1 = delta_o1*input_h1_to_o1\n",
    "gradient_h1_to_o1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "956747c0",
   "metadata": {
    "id": "956747c0"
   },
   "source": [
    "### Calculating Gradient (Hidden Layer)\n",
    "\n",
    "Now, we have to calculate how much the error changes with the change of each weight from input layer to hidden layer i.e. weights stored in **hidden_layer_weights**.\n",
    "\n",
    "*[We are not showing the derivations of the following equations. These can be found in the slides]*\n",
    "\n",
    "$\\frac{\\delta{E_{total}}}{\\delta{w_{i1h1}}}=\\delta_{h1}*input_{i1h1}$\n",
    "\n",
    "$\\frac{\\delta{E_{total}}}{\\delta{w_{i1h1}}}=-(\\delta_{o1}*{w_{h1o1}}+\\delta_{o2}*{w_{h1o2}}+\\delta_{o3}*{w_{h1o3}})*out_{h1}(1-out_{h1})*input_{i1h1}$\n",
    "\n",
    "where ${w_{i1h1}}$ is the weight of the connection between input neuron ${i_1}$ and hidden neuron ${h_1}$, ${out_{h1}}$ is the output of hidden neuron ${h_1}$, ${input_{i1h1}}$ is the input from neuron ${i_1}$ to ${h_1}$.\n",
    "\n",
    "First, calculate ${\\delta_{o1}}$, ${\\delta_{o2}}$ and ${\\delta_{o3}}$ :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "fa2a5b53",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fa2a5b53",
    "outputId": "fa4edc6c-813b-443c-c26d-93de843dd0e0"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.14814111,  0.04042792,  0.0684072 ])"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "expected = sample_output\n",
    "actual = output_layer_output\n",
    "delta_o = -(expected-actual)*actual*(1-actual)\n",
    "delta_o"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc179324",
   "metadata": {
    "id": "cc179324"
   },
   "source": [
    "Now, calculate ${\\delta_{h1}}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "37581b12",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "37581b12",
    "outputId": "69091ba8-3756-4ad8-dbad-19e7732ec6c8"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.206149484245214e-06"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out_h1 = hidden_layer_output[0]\n",
    "delta_h1 = -(sum(delta_o*output_layer_weights[:,0]))*out_h1*(1-out_h1)\n",
    "delta_h1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "8369a7df",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8369a7df",
    "outputId": "595aac2b-7f82-4d35-9ca3-acb37ad932ef"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.8047118002090461e-06"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_i1_to_h1 = sample_input[0]\n",
    "gradient_i1_to_h1 = delta_h1*input_i1_to_h1\n",
    "gradient_i1_to_h1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5aa8dd98",
   "metadata": {
    "id": "5aa8dd98"
   },
   "source": [
    "### Updating Weight (Output Layer)\n",
    "\n",
    "${w_{h1o1}^{+}}={w_{h1o1}}-{\\eta}*{\\frac{\\delta{E_{total}}}{\\delta{w_{h1o1}}}}$\n",
    "\n",
    "where ${\\eta}$ is the learning rate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "516ec3d2",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "516ec3d2",
    "outputId": "c11ff636-306c-4e59-c1ae-65af6c16b702"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.1378320284293175"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learning_rate = 0.5\n",
    "output_layer_weights[0,0] = output_layer_weights[0,0] - learning_rate*gradient_h1_to_o1\n",
    "output_layer_weights[0,0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae803cfd",
   "metadata": {
    "id": "ae803cfd"
   },
   "source": [
    "### Updating Weight (Hidden Layer)\n",
    "\n",
    "${w_{i1h1}^{+}}={w_{i1h1}}-{\\eta}*{\\frac{\\delta{E_{total}}}{\\delta{w_{i1h1}}}}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "9248d1fe",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9248d1fe",
    "outputId": "212f16d0-7e69-4a2d-96a6-fb00840e1d5d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.0762697610747107"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hidden_layer_weights[0,0] = hidden_layer_weights[0,0] - learning_rate*gradient_i1_to_h1\n",
    "hidden_layer_weights[0,0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5233d15e",
   "metadata": {
    "id": "5233d15e"
   },
   "source": [
    "Now, that we have covered all the steps, let us put all of them together to train our NN."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c09f908",
   "metadata": {},
   "source": [
    "# Combining all the steps together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "b3ba407d",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "b3ba407d",
    "outputId": "585199b9-63af-46cb-e912-d942b0cae5e1"
   },
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from random import random\n",
    "\n",
    "#Importing the dataset\n",
    "df = pd.read_csv(\"accelerometer.csv\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "e4946dae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>z</th>\n",
       "      <th>RPM</th>\n",
       "      <th>Weight Config</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>14061</th>\n",
       "      <td>0.961</td>\n",
       "      <td>0.055</td>\n",
       "      <td>-0.109</td>\n",
       "      <td>40</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43202</th>\n",
       "      <td>-0.613</td>\n",
       "      <td>-0.930</td>\n",
       "      <td>0.742</td>\n",
       "      <td>90</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39391</th>\n",
       "      <td>-0.246</td>\n",
       "      <td>1.293</td>\n",
       "      <td>2.934</td>\n",
       "      <td>85</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105199</th>\n",
       "      <td>0.973</td>\n",
       "      <td>0.117</td>\n",
       "      <td>-0.141</td>\n",
       "      <td>25</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8193</th>\n",
       "      <td>1.004</td>\n",
       "      <td>-0.082</td>\n",
       "      <td>-0.148</td>\n",
       "      <td>30</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117400</th>\n",
       "      <td>0.953</td>\n",
       "      <td>0.078</td>\n",
       "      <td>-0.141</td>\n",
       "      <td>45</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102635</th>\n",
       "      <td>0.965</td>\n",
       "      <td>-0.117</td>\n",
       "      <td>-0.113</td>\n",
       "      <td>20</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56637</th>\n",
       "      <td>0.973</td>\n",
       "      <td>0.043</td>\n",
       "      <td>-0.137</td>\n",
       "      <td>25</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30837</th>\n",
       "      <td>0.941</td>\n",
       "      <td>0.008</td>\n",
       "      <td>-0.332</td>\n",
       "      <td>70</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42147</th>\n",
       "      <td>-0.445</td>\n",
       "      <td>-1.078</td>\n",
       "      <td>1.805</td>\n",
       "      <td>90</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>50000 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            x      y      z  RPM  Weight Config\n",
       "14061   0.961  0.055 -0.109   40              1\n",
       "43202  -0.613 -0.930  0.742   90              1\n",
       "39391  -0.246  1.293  2.934   85              1\n",
       "105199  0.973  0.117 -0.141   25              3\n",
       "8193    1.004 -0.082 -0.148   30              1\n",
       "...       ...    ...    ...  ...            ...\n",
       "117400  0.953  0.078 -0.141   45              3\n",
       "102635  0.965 -0.117 -0.113   20              3\n",
       "56637   0.973  0.043 -0.137   25              2\n",
       "30837   0.941  0.008 -0.332   70              1\n",
       "42147  -0.445 -1.078  1.805   90              1\n",
       "\n",
       "[50000 rows x 5 columns]"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Creating our training dataset using 50,000 samples\n",
    "sampled_input_data = df.sample(50000)\n",
    "sampled_input_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "1de7f612",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating normalized dataframe\n",
    "normalized_df=(sampled_input_data-sampled_input_data.min())/(sampled_input_data.max()-sampled_input_data.min())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "01e00669",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>z</th>\n",
       "      <th>RPM</th>\n",
       "      <th>Weight Config</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>14061</th>\n",
       "      <td>0.560203</td>\n",
       "      <td>0.503563</td>\n",
       "      <td>0.494049</td>\n",
       "      <td>0.2500</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43202</th>\n",
       "      <td>0.461803</td>\n",
       "      <td>0.441985</td>\n",
       "      <td>0.578457</td>\n",
       "      <td>0.8750</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39391</th>\n",
       "      <td>0.484746</td>\n",
       "      <td>0.580958</td>\n",
       "      <td>0.795874</td>\n",
       "      <td>0.8125</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105199</th>\n",
       "      <td>0.560953</td>\n",
       "      <td>0.507439</td>\n",
       "      <td>0.490875</td>\n",
       "      <td>0.0625</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8193</th>\n",
       "      <td>0.562891</td>\n",
       "      <td>0.494999</td>\n",
       "      <td>0.490181</td>\n",
       "      <td>0.1250</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117400</th>\n",
       "      <td>0.559702</td>\n",
       "      <td>0.505001</td>\n",
       "      <td>0.490875</td>\n",
       "      <td>0.3125</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102635</th>\n",
       "      <td>0.560453</td>\n",
       "      <td>0.492811</td>\n",
       "      <td>0.493652</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56637</th>\n",
       "      <td>0.560953</td>\n",
       "      <td>0.502813</td>\n",
       "      <td>0.491272</td>\n",
       "      <td>0.0625</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30837</th>\n",
       "      <td>0.558952</td>\n",
       "      <td>0.500625</td>\n",
       "      <td>0.471930</td>\n",
       "      <td>0.6250</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42147</th>\n",
       "      <td>0.472306</td>\n",
       "      <td>0.432733</td>\n",
       "      <td>0.683892</td>\n",
       "      <td>0.8750</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>50000 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               x         y         z     RPM  Weight Config\n",
       "14061   0.560203  0.503563  0.494049  0.2500            0.0\n",
       "43202   0.461803  0.441985  0.578457  0.8750            0.0\n",
       "39391   0.484746  0.580958  0.795874  0.8125            0.0\n",
       "105199  0.560953  0.507439  0.490875  0.0625            1.0\n",
       "8193    0.562891  0.494999  0.490181  0.1250            0.0\n",
       "...          ...       ...       ...     ...            ...\n",
       "117400  0.559702  0.505001  0.490875  0.3125            1.0\n",
       "102635  0.560453  0.492811  0.493652  0.0000            1.0\n",
       "56637   0.560953  0.502813  0.491272  0.0625            0.5\n",
       "30837   0.558952  0.500625  0.471930  0.6250            0.0\n",
       "42147   0.472306  0.432733  0.683892  0.8750            0.0\n",
       "\n",
       "[50000 rows x 5 columns]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "normalized_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "92723838",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Build the ANN\n",
    "n_input = len(normalized_df.iloc[0])-1\n",
    "n_hidden = 5\n",
    "n_output = len(pd.unique(normalized_df['Weight Config']))\n",
    "\n",
    "#Initialize the weights\n",
    "hidden_layer_weights = np.asarray([[random() for i in range(n_input + 1)] for i in range(n_hidden)])\n",
    "output_layer_weights = np.asarray([[random() for i in range(n_hidden + 1)] for i in range(n_output)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "b0ae1605",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Input data to our neural network\n",
    "input_data = normalized_df.iloc[:,0:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "ecb82c47",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>z</th>\n",
       "      <th>RPM</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>14061</th>\n",
       "      <td>0.560203</td>\n",
       "      <td>0.503563</td>\n",
       "      <td>0.494049</td>\n",
       "      <td>0.2500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43202</th>\n",
       "      <td>0.461803</td>\n",
       "      <td>0.441985</td>\n",
       "      <td>0.578457</td>\n",
       "      <td>0.8750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39391</th>\n",
       "      <td>0.484746</td>\n",
       "      <td>0.580958</td>\n",
       "      <td>0.795874</td>\n",
       "      <td>0.8125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105199</th>\n",
       "      <td>0.560953</td>\n",
       "      <td>0.507439</td>\n",
       "      <td>0.490875</td>\n",
       "      <td>0.0625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8193</th>\n",
       "      <td>0.562891</td>\n",
       "      <td>0.494999</td>\n",
       "      <td>0.490181</td>\n",
       "      <td>0.1250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117400</th>\n",
       "      <td>0.559702</td>\n",
       "      <td>0.505001</td>\n",
       "      <td>0.490875</td>\n",
       "      <td>0.3125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102635</th>\n",
       "      <td>0.560453</td>\n",
       "      <td>0.492811</td>\n",
       "      <td>0.493652</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56637</th>\n",
       "      <td>0.560953</td>\n",
       "      <td>0.502813</td>\n",
       "      <td>0.491272</td>\n",
       "      <td>0.0625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30837</th>\n",
       "      <td>0.558952</td>\n",
       "      <td>0.500625</td>\n",
       "      <td>0.471930</td>\n",
       "      <td>0.6250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42147</th>\n",
       "      <td>0.472306</td>\n",
       "      <td>0.432733</td>\n",
       "      <td>0.683892</td>\n",
       "      <td>0.8750</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>50000 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               x         y         z     RPM\n",
       "14061   0.560203  0.503563  0.494049  0.2500\n",
       "43202   0.461803  0.441985  0.578457  0.8750\n",
       "39391   0.484746  0.580958  0.795874  0.8125\n",
       "105199  0.560953  0.507439  0.490875  0.0625\n",
       "8193    0.562891  0.494999  0.490181  0.1250\n",
       "...          ...       ...       ...     ...\n",
       "117400  0.559702  0.505001  0.490875  0.3125\n",
       "102635  0.560453  0.492811  0.493652  0.0000\n",
       "56637   0.560953  0.502813  0.491272  0.0625\n",
       "30837   0.558952  0.500625  0.471930  0.6250\n",
       "42147   0.472306  0.432733  0.683892  0.8750\n",
       "\n",
       "[50000 rows x 4 columns]"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "9ddff74b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Input data + Bias\n",
    "input_data = np.append(input_data,np.ones((len(input_data),1)),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "9aeb091b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.56020255, 0.50356339, 0.4940488 , 0.25      , 1.        ],\n",
       "       [0.46180295, 0.4419855 , 0.57845666, 0.875     , 1.        ],\n",
       "       [0.48474619, 0.58095774, 0.79587383, 0.8125    , 1.        ],\n",
       "       ...,\n",
       "       [0.56095274, 0.5028132 , 0.49127157, 0.0625    , 1.        ],\n",
       "       [0.55895224, 0.50062516, 0.47193017, 0.625     , 1.        ],\n",
       "       [0.47230558, 0.43273318, 0.68389208, 0.875     , 1.        ]])"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "4fcc7b31",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Expected/Ideal output\n",
    "\n",
    "expected_output = np.zeros((len(input_data),3))\n",
    "class_labels = sampled_input_data.iloc[:,-1]\n",
    "\n",
    "#Expected/Ideal output (binary)\n",
    "for idx, label in enumerate(class_labels):\n",
    "    expected_output[idx,label-1] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "9ac23471",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Initializing arrays to store delta values  \n",
    "delta_output = np.zeros((n_output))\n",
    "delta_hidden = np.zeros((n_hidden))\n",
    "\n",
    "#Initializing arrays to store gradient values\n",
    "\n",
    "gradient_output_weights = np.zeros(output_layer_weights.shape)\n",
    "gradient_hidden_weights = np.zeros(hidden_layer_weights.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "c86a6f06",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Initializing arrays to store net input value to each neuron\n",
    "\n",
    "hidden_net_input = np.zeros((len(input_data),n_hidden))\n",
    "output_net_input = np.zeros((len(input_data),n_output))\n",
    "\n",
    "#Initializing arrays to store output value of each neuron\n",
    "\n",
    "hidden_layer_output = np.zeros((len(input_data),n_hidden))\n",
    "output_layer_output = np.zeros((len(input_data),n_output))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "badc3b2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define number of epochs for which the NN will be trained\n",
    "n_epochs = 100\n",
    "\n",
    "#Define the learning rate\n",
    "lr = 0.5\n",
    "\n",
    "#Initializing array to store error values of each epoch\n",
    "error = np.zeros((n_epochs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "92abd50e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  0  Error:  0.35414467899544033\n",
      "Epoch:  1  Error:  0.3541197075426863\n",
      "Epoch:  2  Error:  0.35411025449786293\n",
      "Epoch:  3  Error:  0.35410518987625006\n",
      "Epoch:  4  Error:  0.35410200193508123\n",
      "Epoch:  5  Error:  0.35409979693540367\n",
      "Epoch:  6  Error:  0.3540981740630075\n",
      "Epoch:  7  Error:  0.35409692577721363\n",
      "Epoch:  8  Error:  0.35409593344022905\n",
      "Epoch:  9  Error:  0.3540951241304301\n",
      "Epoch:  10  Error:  0.35409445046149607\n",
      "Epoch:  11  Error:  0.3540938802528629\n",
      "Epoch:  12  Error:  0.3540933908533967\n",
      "Epoch:  13  Error:  0.3540929658389153\n",
      "Epoch:  14  Error:  0.3540925929984746\n",
      "Epoch:  15  Error:  0.3540922630572482\n",
      "Epoch:  16  Error:  0.3540919688390127\n",
      "Epoch:  17  Error:  0.3540917047008668\n",
      "Epoch:  18  Error:  0.35409146614200165\n",
      "Epoch:  19  Error:  0.35409124952689697\n",
      "Epoch:  20  Error:  0.35409105188561174\n",
      "Epoch:  21  Error:  0.3540908707671639\n",
      "Epoch:  22  Error:  0.3540907041301913\n",
      "Epoch:  23  Error:  0.35409055026024894\n",
      "Epoch:  24  Error:  0.3540904077064517\n",
      "Epoch:  25  Error:  0.3540902752323627\n",
      "Epoch:  26  Error:  0.3540901517775149\n",
      "Epoch:  27  Error:  0.3540900364269681\n",
      "Epoch:  28  Error:  0.3540899283870007\n",
      "Epoch:  29  Error:  0.3540898269655389\n",
      "Epoch:  30  Error:  0.35408973155627504\n",
      "Epoch:  31  Error:  0.35408964162568674\n",
      "Epoch:  32  Error:  0.354089556702356\n",
      "Epoch:  33  Error:  0.35408947636812294\n",
      "Epoch:  34  Error:  0.35408940025071733\n",
      "Epoch:  35  Error:  0.35408932801758625\n",
      "Epoch:  36  Error:  0.35408925937069546\n",
      "Epoch:  37  Error:  0.3540891940421322\n",
      "Epoch:  38  Error:  0.3540891317903648\n",
      "Epoch:  39  Error:  0.35408907239704995\n",
      "Epoch:  40  Error:  0.35408901566429435\n",
      "Epoch:  41  Error:  0.3540889614122975\n",
      "Epoch:  42  Error:  0.35408890947731453\n",
      "Epoch:  43  Error:  0.35408885970988985\n",
      "Epoch:  44  Error:  0.3540888119733203\n",
      "Epoch:  45  Error:  0.3540887661423123\n",
      "Epoch:  46  Error:  0.35408872210180786\n",
      "Epoch:  47  Error:  0.3540886797459514\n",
      "Epoch:  48  Error:  0.3540886389771811\n",
      "Epoch:  49  Error:  0.3540885997054263\n",
      "Epoch:  50  Error:  0.3540885618473959\n",
      "Epoch:  51  Error:  0.35408852532594803\n",
      "Epoch:  52  Error:  0.3540884900695279\n",
      "Epoch:  53  Error:  0.3540884560116675\n",
      "Epoch:  54  Error:  0.35408842309053745\n",
      "Epoch:  55  Error:  0.3540883912485469\n",
      "Epoch:  56  Error:  0.3540883604319831\n",
      "Epoch:  57  Error:  0.3540883305906875\n",
      "Epoch:  58  Error:  0.35408830167776534\n",
      "Epoch:  59  Error:  0.354088273649321\n",
      "Epoch:  60  Error:  0.3540882464642214\n",
      "Epoch:  61  Error:  0.3540882200838793\n",
      "Epoch:  62  Error:  0.35408819447205864\n",
      "Epoch:  63  Error:  0.3540881695946957\n",
      "Epoch:  64  Error:  0.35408814541973876\n",
      "Epoch:  65  Error:  0.35408812191699934\n",
      "Epoch:  66  Error:  0.3540880990580185\n",
      "Epoch:  67  Error:  0.35408807681594295\n",
      "Epoch:  68  Error:  0.3540880551654135\n",
      "Epoch:  69  Error:  0.3540880340824607\n",
      "Epoch:  70  Error:  0.3540880135444109\n",
      "Epoch:  71  Error:  0.3540879935297988\n",
      "Epoch:  72  Error:  0.3540879740182876\n",
      "Epoch:  73  Error:  0.354087954990595\n",
      "Epoch:  74  Error:  0.35408793642842495\n",
      "Epoch:  75  Error:  0.35408791831440584\n",
      "Epoch:  76  Error:  0.354087900632031\n",
      "Epoch:  77  Error:  0.35408788336560637\n",
      "Epoch:  78  Error:  0.35408786650019997\n",
      "Epoch:  79  Error:  0.35408785002159576\n",
      "Epoch:  80  Error:  0.3540878339162514\n",
      "Epoch:  81  Error:  0.35408781817125845\n",
      "Epoch:  82  Error:  0.35408780277430424\n",
      "Epoch:  83  Error:  0.35408778771363997\n",
      "Epoch:  84  Error:  0.3540877729780456\n",
      "Epoch:  85  Error:  0.3540877585568029\n",
      "Epoch:  86  Error:  0.35408774443966573\n",
      "Epoch:  87  Error:  0.3540877306168347\n",
      "Epoch:  88  Error:  0.354087717078933\n",
      "Epoch:  89  Error:  0.35408770381698335\n",
      "Epoch:  90  Error:  0.3540876908223871\n",
      "Epoch:  91  Error:  0.35408767808690417\n",
      "Epoch:  92  Error:  0.3540876656026345\n",
      "Epoch:  93  Error:  0.3540876533620002\n",
      "Epoch:  94  Error:  0.3540876413577295\n",
      "Epoch:  95  Error:  0.35408762958284135\n",
      "Epoch:  96  Error:  0.3540876180306307\n",
      "Epoch:  97  Error:  0.354087606694655\n",
      "Epoch:  98  Error:  0.3540875955687215\n",
      "Epoch:  99  Error:  0.3540875846468745\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(n_epochs):\n",
    "    \n",
    "    for i, row in enumerate(input_data):\n",
    "        \n",
    "        for j, layer in enumerate(hidden_layer_weights):\n",
    "            \n",
    "            #Calculating net input to each hidden neuron\n",
    "            hidden_net_input[i,j] = sum(row*layer)\n",
    "            \n",
    "            #Applying activation function and calculating output of each hidden neuron\n",
    "            hidden_layer_output[i,j] = 1/(1+math.exp(-hidden_net_input[i,j]))\n",
    "        \n",
    "        #Input from hidden neurons to output neurons + Bias\n",
    "        input_hidden_to_output = np.append(hidden_layer_output[i,:],[1])\n",
    "        \n",
    "        for j, layer in enumerate(output_layer_weights):\n",
    "            \n",
    "            #Calculating net input to each output neuron'''\n",
    "            output_net_input[i,j] = sum(input_hidden_to_output*layer)\n",
    "            \n",
    "            #Applying activation function and calculating output of each output neuron\n",
    "            output_layer_output[i,j] = 1/(1+math.exp(-output_net_input[i,j]))\n",
    "            \n",
    "        #Calculating total error    \n",
    "        error[epoch] = sum(0.5*((expected_output[i,:]-output_layer_output[i,:])**2))\n",
    "        \n",
    "        #Calculating delta of output neurons\n",
    "        delta_output = -(expected_output[i,:]-output_layer_output[i,:])*output_layer_output[i,:]*(1-output_layer_output[i,:])\n",
    "        \n",
    "        #Calculating gradients of output layer weights\n",
    "        for j, delta in enumerate(delta_output):\n",
    "            gradient_output_weights[j,:] = delta*input_hidden_to_output\n",
    "        \n",
    "        #Calculating delta of hidden neurons\n",
    "        for j in range(n_hidden):\n",
    "            delta_hidden[j] = -(sum(delta_output*output_layer_weights[:,j]))*hidden_layer_output[i,j]*(1-hidden_layer_output[i,j])\n",
    "        \n",
    "        #Calculating gradient of hidden layer weights\n",
    "        for j, delta in enumerate(delta_hidden):\n",
    "            gradient_hidden_weights[j,:] = delta*row\n",
    "        \n",
    "        #Updating the weights\n",
    "        output_layer_weights = output_layer_weights-(lr*gradient_output_weights)\n",
    "        hidden_layer_weights = hidden_layer_weights-(lr*gradient_hidden_weights)\n",
    "        \n",
    "    print(\"Epoch: \",epoch,\" Error: \",error[epoch])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "9253f5fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x2387891fdc0>]"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Plot the error with epochs\n",
    "import matplotlib.pyplot as plt\n",
    "plt.plot(np.arange(epoch + 1), error )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6Q1XW7bjgAJ",
   "metadata": {
    "id": "a6Q1XW7bjgAJ"
   },
   "source": [
    "**Train the Neural Network again by changing the number of epochs, learning rate, number of hidden layers, and size of training data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "904913ea",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
