{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3c2ee2b2",
   "metadata": {
    "id": "3c2ee2b2"
   },
   "source": [
    "# Keras Tuner\n",
    "[Keras Tuner](https://keras.io/api/keras_tuner/) is an open-source python library developed exclusively for tuning the hyperparameters of ANN and CNN. Keras tuner currently supports four types of tuners or algorithms namely,\n",
    "1. Bayesian Optimization\n",
    "2. Hyperband\n",
    "3. Sklearn\n",
    "4. Random Search\n",
    "\n",
    "You can instakk the Keras tyner on your system using the following command,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7b6af48",
   "metadata": {
    "id": "d7b6af48"
   },
   "outputs": [],
   "source": [
    "#!pip install keras-tuner"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e71a0601",
   "metadata": {
    "id": "e71a0601"
   },
   "source": [
    "In this tutorial we will do regression on boston housing dataset. Firstly, without using Keras Tuner and then using keras tuner.\n",
    "## Without Keras Tuner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dd10e80b",
   "metadata": {
    "id": "dd10e80b"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import keras_tuner\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2c30d0aa",
   "metadata": {
    "id": "2c30d0aa"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/boston_housing.npz\n",
      "57344/57026 [==============================] - 0s 0us/step\n",
      "65536/57026 [==================================] - 0s 0us/step\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.datasets import boston_housing\n",
    "(X_train, y_train), (X_test, y_test) = boston_housing.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ac537546",
   "metadata": {
    "id": "ac537546"
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from tensorflow.keras import models, layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8975cf11",
   "metadata": {
    "id": "8975cf11"
   },
   "outputs": [],
   "source": [
    "# set random seed\n",
    "from numpy.random import seed\n",
    "seed(42)\n",
    "import tensorflow\n",
    "tensorflow.random.set_seed(42)\n",
    "\n",
    "# preprocessing - normalization\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train)\n",
    "X_train_scaled = scaler.transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5724de03",
   "metadata": {
    "id": "5724de03"
   },
   "outputs": [],
   "source": [
    "# model building\n",
    "model = models.Sequential()\n",
    "model.add(layers.Dense(8, activation='relu', input_shape=(X_train.shape[1],)))\n",
    "model.add(layers.Dense(16, activation='relu'))\n",
    "model.add(layers.Dropout(0.1))\n",
    "model.add(layers.Dense(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7bdf2d68",
   "metadata": {
    "id": "7bdf2d68"
   },
   "outputs": [],
   "source": [
    "# compile model using rmsprop\n",
    "model.compile(optimizer='rmsprop',loss='mse',metrics=['mse'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4a44ca43",
   "metadata": {
    "id": "4a44ca43",
    "outputId": "80c91395-d2a2-4dab-b1aa-72375effee9b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "11/11 [==============================] - 3s 71ms/step - loss: 572.4401 - mse: 572.4401 - val_loss: 636.1214 - val_mse: 636.1214\n",
      "Epoch 2/10\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 559.4045 - mse: 559.4045 - val_loss: 623.9985 - val_mse: 623.9985\n",
      "Epoch 3/10\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 548.9240 - mse: 548.9240 - val_loss: 613.4424 - val_mse: 613.4424\n",
      "Epoch 4/10\n",
      "11/11 [==============================] - 0s 16ms/step - loss: 538.9026 - mse: 538.9026 - val_loss: 601.6938 - val_mse: 601.6938\n",
      "Epoch 5/10\n",
      "11/11 [==============================] - 0s 18ms/step - loss: 528.5445 - mse: 528.5445 - val_loss: 589.8356 - val_mse: 589.8356\n",
      "Epoch 6/10\n",
      "11/11 [==============================] - 0s 16ms/step - loss: 518.9130 - mse: 518.9130 - val_loss: 576.8784 - val_mse: 576.8784\n",
      "Epoch 7/10\n",
      "11/11 [==============================] - 0s 27ms/step - loss: 506.5880 - mse: 506.5880 - val_loss: 563.4048 - val_mse: 563.4048\n",
      "Epoch 8/10\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 494.0285 - mse: 494.0285 - val_loss: 548.2653 - val_mse: 548.2653\n",
      "Epoch 9/10\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 479.5580 - mse: 479.5580 - val_loss: 534.1605 - val_mse: 534.1605\n",
      "Epoch 10/10\n",
      "11/11 [==============================] - 0s 21ms/step - loss: 466.3437 - mse: 466.3437 - val_loss: 518.9818 - val_mse: 518.9818\n"
     ]
    }
   ],
   "source": [
    "# model training\n",
    "history = model.fit(X_train_scaled, y_train, validation_split=0.2, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cc070dfe",
   "metadata": {
    "id": "cc070dfe",
    "outputId": "79d4d9e9-b36d-47fe-d825-46b1731c03cf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 4ms/step - loss: 486.4476 - mse: 486.4476\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[486.4476013183594, 486.4476013183594]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# model evaluation\n",
    "model.evaluate(X_test_scaled, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90d58a41",
   "metadata": {
    "id": "90d58a41"
   },
   "source": [
    "This model has a MSE of around $486.4476$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35d04883",
   "metadata": {
    "id": "35d04883"
   },
   "source": [
    "# HyperParameters\n",
    "The Hyperparameters class is used to specify a set of hyperparameters and their values, to be used in the model building function.\n",
    "\n",
    "* **HyperParameters class**\n",
    "* **Boolean method**\n",
    "* **Choice method**\n",
    "* **Fixed method**\n",
    "* **Float method**\n",
    "* **Int method**\n",
    "* **conditional_scope method**\n",
    "* **get method**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5a48f11",
   "metadata": {
    "id": "a5a48f11"
   },
   "source": [
    "## HyperParameter Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "55391d10",
   "metadata": {
    "id": "55391d10",
    "outputId": "9e760fa8-d943-4896-8f80-34f795e58434"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras_tuner.engine.hyperparameters.hyperparameters.HyperParameters at 0x1c6272c1970>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keras_tuner.HyperParameters()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "964a2923",
   "metadata": {
    "id": "964a2923"
   },
   "source": [
    "**Attributes**\n",
    "* **values**: A dict mapping hyperparameter names to current values."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43e390d3",
   "metadata": {
    "id": "43e390d3"
   },
   "source": [
    "## Boolean Method\n",
    "Choice between True and False\n",
    "\n",
    "**Arguments**\n",
    "* **name**: A string. the name of parameter. Must be unique for each HyperParameter instance in the search space.\n",
    "* **default**: Boolean, the default value to return for the parameter. If unspecified, the default value will be False.\n",
    "* **parent_name**: Optional string, specifying the name of the parent HyperParameter to use as the condition to activate the current HyperParameter.\n",
    "* **parent_values**: Optional list of the values of the parent HyperParameter to use as the condition to activate the current HyperParameter.\n",
    "\n",
    "**Returns**\n",
    "\n",
    "The value of the hyperparameter, or None if the hyperparameter is not active."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f3aca68",
   "metadata": {
    "id": "9f3aca68"
   },
   "source": [
    "## Choice Method\n",
    "Choice of one value among a predefined set of possible values.\n",
    "\n",
    "**Arguments**\n",
    "* **name**: A string. the name of parameter. Must be unique for each HyperParameter instance in the search space.\n",
    "* **values**: A list of possible values. Values must be int, float, str, or bool. All values must be of the same type.\n",
    "* **ordered**: Optional boolean, whether the values passed should be considered to have an ordering. Defaults to True for float/int values. Must be False for any other values.\n",
    "* **default**: Optional default value to return for the parameter. If unspecified, the default value will be: - None if None is one of the choices in values - The first entry in values otherwise.\n",
    "* **parent_name**: Optional string, specifying the name of the parent HyperParameter to use as the condition to activate the current HyperParameter.\n",
    "* **parent_values**: Optional list of the values of the parent HyperParameter to use as the condition to activate the current HyperParameter.\n",
    "\n",
    "**Returns**\n",
    "\n",
    "The value of the hyperparameter, or None if the hyperparameter is not active."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "005d639d",
   "metadata": {
    "id": "005d639d"
   },
   "source": [
    "## Fixed Method\n",
    "Fixed, untunable value.\n",
    "\n",
    "**Arguments**\n",
    "* **name**: A string. the name of parameter. Must be unique for each *HyperParameter* instance in the search space.\n",
    "* **value**: The value to use (can be any JSON-serializable Python type).\n",
    "* **parent_name**: Optional string, specifying the name of the parent *HyperParameter* to use as the condition to activate the current *HyperParameter*.\n",
    "* **parent_values**: Optional list of the values of the parent HyperParameter to use as the condition to activate the current HyperParameter.\n",
    "\n",
    "**Returns**\n",
    "\n",
    "The value of the hyperparameter, or None if the hyperparameter is not active."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9faabce",
   "metadata": {
    "id": "a9faabce"
   },
   "source": [
    "## Float Method\n",
    "Floating point range, can be evenly divided.\n",
    "\n",
    "**Arguments**\n",
    "* **name**: A string. the name of parameter. Must be unique for each HyperParameter instance in the search space.\n",
    "* **min_value**: Float, the lower bound of the range.\n",
    "* **max_value**: Float, the upper bound of the range.\n",
    "* **step**: Optional float, e.g. 0.1, the smallest meaningful distance between two values. Whether step should be specified is Oracle dependent, since some Oracles can infer an optimal step automatically.\n",
    "* **sampling**: Optional string. One of \"linear\", \"log\", \"reverse_log\". Acts as a hint for an initial prior probability distribution for how this value should be sampled, e.g. \"log\" will assign equal probabilities to each order of magnitude range.\n",
    "* **default**: Float, the default value to return for the parameter. If unspecified, the default value will be min_value.\n",
    "* **parent_name**: Optional string, specifying the name of the parent HyperParameter to use as the condition to activate the current HyperParameter.\n",
    "* **parent_values**: Optional list of the values of the parent HyperParameter to use as the condition to activate the current HyperParameter.\n",
    "\n",
    "**Results**\n",
    "\n",
    "The value of the hyperparameter, or None if the hyperparameter is not active."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a3903bb",
   "metadata": {
    "id": "4a3903bb"
   },
   "source": [
    "## Int Method\n",
    "Integer range.\n",
    "\n",
    "Note that unlike Python's range function, max_value is included in the possible values this parameter can take on.\n",
    "\n",
    "**Arguments**\n",
    "\n",
    "* **name**: A string. the name of parameter. Must be unique for each HyperParameter instance in the search space.\n",
    "* **min_value**: Integer, the lower limit of range, inclusive.\n",
    "* **max_value**: Integer, the upper limit of range, inclusive.\n",
    "* **step**: Integer, the distance between two consecutive samples in the range. Defaults to 1.\n",
    "* **sampling**: Optional string. One of \"linear\", \"log\", \"reverse_log\". Acts as a hint for an initial prior probability distribution for how this value should be sampled, e.g. \"log\" will assign equal probabilities to each order of magnitude range.\n",
    "* **default**: Integer, default value to return for the parameter. If unspecified, the default value will be min_value.\n",
    "* **parent_name**: Optional string, specifying the name of the parent HyperParameter to use as the condition to activate the current HyperParameter.\n",
    "* **parent_values**: Optional list of the values of the parent HyperParameter to use as the condition to activate the current HyperParameter.\n",
    "\n",
    "**Returns**\n",
    "\n",
    "The value of the hyperparameter, or None if the hyperparameter is not active."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5362465",
   "metadata": {
    "id": "e5362465"
   },
   "source": [
    "## Conditional_scope Method\n",
    "Opens a scope to create conditional HyperParameters.\n",
    "\n",
    "All **HyperParameters** created under this scope will only be active when the parent **HyperParameter** specified by **parent_name** is equal to one of the values passed in **parent_values**.\n",
    "\n",
    "When the condition is not met, creating a **HyperParameter** under this scope will register the **HyperParameter**, but will return **None** rather than a concrete value.\n",
    "\n",
    "Note that any Python code under this scope will execute regardless of whether the condition is met.\n",
    "\n",
    "This feature is for the **Tuner** to collect more information of the search space and the current trial. It is especially useful for model selection. If the parent **HyperParameter** is for model selection, the **HyperParameters** in a model should only be active when the model selected, which can be implemented using **conditional_scope**.\n",
    "\n",
    "**Arguments**\n",
    "\n",
    "* **parent_name**: A string, specifying the name of the parent HyperParameter to use as the condition to activate the current HyperParameter.\n",
    "* **parent_values**: A list of the values of the parent HyperParameter to use as the condition to activate the current HyperParameter.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b29dbc2",
   "metadata": {
    "id": "2b29dbc2"
   },
   "source": [
    "# Tuning with Keras Tuner\n",
    "To start tuning the model in keras tuner, let’s define a hypermodel first. **Hypermodel** is a keras tuner class that lets you define the model with a searchable space and build it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "62d6f128",
   "metadata": {
    "id": "62d6f128"
   },
   "outputs": [],
   "source": [
    "from keras_tuner import HyperModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "882f2d4b",
   "metadata": {
    "id": "882f2d4b"
   },
   "outputs": [],
   "source": [
    "class RegressionHyperModel(HyperModel):\n",
    "    def __init__(self, input_shape):\n",
    "        self.input_shape = input_shape\n",
    "    def build(self, hp):\n",
    "        model = keras.Sequential()\n",
    "        model.add(layers.Dense(units=hp.Int('units',min_value = 8, max_value = 64, step = 4, default=8),\n",
    "                activation=hp.Choice('dense_activation',values=['relu', 'tanh', 'sigmoid'],default='relu'),\n",
    "                input_shape=input_shape))\n",
    "        \n",
    "        model.add(layers.Dense(units=hp.Int('units', min_value = 16, max_value = 64, step = 4, default=16),\n",
    "                activation=hp.Choice('dense_activation',values=['relu', 'tanh', 'sigmoid'],default='relu')))\n",
    "        \n",
    "        model.add(layers.Dropout(hp.Float('dropout',min_value=0.0,max_value=0.1,default=0.005,step=0.01)))\n",
    "        \n",
    "        model.add(layers.Dense(1))\n",
    "        \n",
    "        model.compile(optimizer='rmsprop',loss='mse',metrics=['mse'])\n",
    "        \n",
    "        return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a63c9206",
   "metadata": {
    "id": "a63c9206"
   },
   "source": [
    "You may have noticed **hp.Int**, **hp.Float**, and **hp.Choice**, these are used to define a search space for a hyperparameter that accepts an integer, float and a category respectively. A complete list of hyperparameter methods can be found above. **'hp'** is an alias for Keras Tuner's HyperParameters class."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1a7d124",
   "metadata": {
    "id": "b1a7d124"
   },
   "source": [
    "Hyperparameter such as the number of units in a dense layer accepts an integer, hence, **hp.Int** is used to define a range of integers to try. Similarly, the dropout rate accepts a float value so **hp.Float** is used. Both **hp.Int** and **hp.Float** requires a name, minimum value and maximum value, while the step size and default value is optional.\n",
    "\n",
    "The **hp.Int** search space below is named, **\"units\"**, and will have values from $8$ to $64$ in multiples of $4$, and a default value of $8$. **hp.Float** is used similarly as **hp.Int** but accepts float values.\n",
    "\n",
    "**hp.Choice** is used to define a categorical hyperparameter such as the activation function. The search space below, named \"dense_activation\", will choose between \"relu\", \"tanh\", and \"sigmoid\" functions, with a default value set to \"relu\"."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2b33b86",
   "metadata": {
    "id": "e2b33b86"
   },
   "source": [
    "## Instantiate HyperModel\n",
    "Let’s instantiate a hypermodel object. Input shape varies per dataset and the problem you are trying to solve."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "1c5acd92",
   "metadata": {
    "id": "1c5acd92"
   },
   "outputs": [],
   "source": [
    "input_shape = (X_train.shape[1],)\n",
    "hypermodel = RegressionHyperModel(input_shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cadeae37",
   "metadata": {
    "id": "cadeae37"
   },
   "source": [
    "### Random Search\n",
    "As the name suggests, this hyperparameter tuning method randomly tries a combination of hyperparameters from a given search space. To use this method in keras tuner, let’s define a tuner using one of the available Tuners."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a1aad977",
   "metadata": {
    "id": "a1aad977"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Reloading Tuner from .\\untitled_project\\tuner0.json\n"
     ]
    }
   ],
   "source": [
    "tuner_rs = keras_tuner.RandomSearch(hypermodel, objective='mse', seed=42, max_trials=10, executions_per_trial=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dbb91e6",
   "metadata": {
    "id": "3dbb91e6"
   },
   "source": [
    "Run the random search tuner using the search method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "8bf0c9d1",
   "metadata": {
    "id": "8bf0c9d1",
    "outputId": "267d23bb-d9fb-4315-ec0d-8ec975fcb3b7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Oracle triggered exit\n"
     ]
    }
   ],
   "source": [
    "tuner_rs.search(X_train_scaled, y_train, epochs=10, validation_split=0.2, verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33959e03",
   "metadata": {
    "id": "33959e03"
   },
   "source": [
    "In the next cells, we have retrieved the best model and used it to evaluate performance on the test dataset which we had used as a validation dataset. Then, we have printed the tuning summary as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "2850468f",
   "metadata": {
    "id": "2850468f",
    "outputId": "4ee91916-8e9f-45bc-b3cf-fd8a2037def3"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'units': 60, 'dense_activation': 'relu', 'dropout': 0.1}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_params = tuner_rs.get_best_hyperparameters()\n",
    "\n",
    "best_params[0].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a582f436",
   "metadata": {
    "id": "a582f436",
    "outputId": "afd3a1c7-4ad1-4d41-db95-6aa7cf63cbb8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 1s 4ms/step - loss: 50.6940 - mse: 50.6940\n"
     ]
    }
   ],
   "source": [
    "best_model = tuner_rs.get_best_models(num_models=1)[0]\n",
    "loss, mse = best_model.evaluate(X_test_scaled, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11a8865f",
   "metadata": {
    "id": "11a8865f"
   },
   "source": [
    "Random search's MSE is $50.69$, a very big improvement from not performing any tuning at all."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85034a6c",
   "metadata": {
    "id": "85034a6c"
   },
   "source": [
    "### Hyperband\n",
    "Hyperband is based on the algorithm by Li et. al. It optimizes random search method through adaptive resource allocation and early-stopping. Hyperband first runs random hyperparameter configurations for one iteration or two, then selects which configurations perform well, then continues tuning the best performers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "74494fef",
   "metadata": {
    "id": "74494fef",
    "outputId": "3330c0ab-a01b-4784-a306-7032b71a720b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 20 Complete [00h 00m 03s]\n",
      "mse: 530.1045532226562\n",
      "\n",
      "Best mse So Far: 215.310302734375\n",
      "Total elapsed time: 00h 01m 03s\n",
      "INFO:tensorflow:Oracle triggered exit\n"
     ]
    }
   ],
   "source": [
    "tuner_hb = keras_tuner.Hyperband(hypermodel, max_epochs=5, objective='mse', seed=42, hyperband_iterations=2, overwrite = True)\n",
    "tuner_hb.search(X_train_scaled, y_train, epochs=10, validation_split=0.2, verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cfb9269",
   "metadata": {
    "id": "1cfb9269"
   },
   "source": [
    "In the next cells, we have retrieved the best model and used it to evaluate performance on the test dataset which we had used as a validation dataset. Then, we have printed the tuning summary as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "cd920739",
   "metadata": {
    "id": "cd920739",
    "outputId": "be5a9b18-4291-41f6-d5a2-4e6c28a15dfd"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'units': 60,\n",
       " 'dense_activation': 'relu',\n",
       " 'dropout': 0.1,\n",
       " 'tuner/epochs': 5,\n",
       " 'tuner/initial_epoch': 2,\n",
       " 'tuner/bracket': 1,\n",
       " 'tuner/round': 1,\n",
       " 'tuner/trial_id': '0004'}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_params = tuner_hb.get_best_hyperparameters()\n",
    "\n",
    "best_params[0].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "9fe0c478",
   "metadata": {
    "id": "9fe0c478",
    "outputId": "f790f600-815c-49f3-d41b-b5040c9749bd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 3ms/step - loss: 207.0387 - mse: 207.0387\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[207.03868103027344, 207.03868103027344]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_model = tuner_hb.get_best_models(num_models=1)[0]\n",
    "best_model.evaluate(X_test_scaled, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffc18ca8",
   "metadata": {
    "id": "ffc18ca8"
   },
   "source": [
    "The resulting MSE is $207.03$ which is a lot worse when compared to random search but a little bit better than not tuning at all."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38bbcbe9",
   "metadata": {
    "id": "38bbcbe9"
   },
   "source": [
    "### Bayesian Optimization\n",
    "Bayesian optimization is a probabilistic model that maps the hyperparameters to a probability score on the objective function. Unlike Random Search and Hyperband models, Bayesian Optimization keeps track of its past evaluation results and uses it to build the probability model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "0c3fe943",
   "metadata": {
    "id": "0c3fe943",
    "outputId": "c90d79c6-302d-41cb-df64-df6ff66cea8a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 10 Complete [00h 00m 08s]\n",
      "mse: 42.36796474456787\n",
      "\n",
      "Best mse So Far: 42.36796474456787\n",
      "Total elapsed time: 00h 01m 27s\n",
      "INFO:tensorflow:Oracle triggered exit\n"
     ]
    }
   ],
   "source": [
    "tuner_bo = keras_tuner.BayesianOptimization(hypermodel, objective='mse', max_trials=10, seed=42, executions_per_trial=2, overwrite = True)\n",
    "tuner_bo.search(X_train_scaled, y_train, epochs=10, validation_split=0.2, verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fa167fb",
   "metadata": {
    "id": "1fa167fb"
   },
   "source": [
    "In the next cells, we have retrieved the best model and used it to evaluate performance on the test dataset which we had used as a validation dataset. Then, we have printed the tuning summary as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "7b404f83",
   "metadata": {
    "id": "7b404f83",
    "outputId": "6e992c3a-631d-4bee-995f-1f493a43b893"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'units': 64, 'dense_activation': 'relu', 'dropout': 0.05}"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_params = tuner_bo.get_best_hyperparameters()\n",
    "\n",
    "best_params[0].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "0d2464b4",
   "metadata": {
    "id": "0d2464b4",
    "outputId": "8d6fa052-ea13-4658-b8e4-89d26cd194f2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 4ms/step - loss: 32.3583 - mse: 32.3583\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[32.35834884643555, 32.35834884643555]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_model = tuner_bo.get_best_models(num_models=1)[0]\n",
    "best_model.evaluate(X_test_scaled, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79b0b65d",
   "metadata": {
    "id": "79b0b65d"
   },
   "source": [
    "Best model MSE tuned using Bayesian optimization is $32.358$, better than the first two tuners we have tried."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbcfc7a9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
