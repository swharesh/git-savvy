{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "93f4794e",
   "metadata": {
    "id": "93f4794e"
   },
   "source": [
    "# Image Segmentation\n",
    "Image segmentation is a computer vision technique that involves partitioning an image into multiple regions or segments based on the characteristics of the pixels or their features. The goal is to identify and extract meaningful information from an image, such as objects or regions of interest.\n",
    "\n",
    "Image segmentation algorithms typically assign a label or identifier to each pixel based on its color, intensity, texture, or other features. This results in a pixel-wise labeling of the image, which can be used for various tasks such as object recognition, object tracking, image editing, and more.\n",
    "\n",
    "There are various approaches to image segmentation, such as thresholding, edge detection, region growing, clustering, and deep learning-based methods. These techniques can be applied to a wide range of applications such as medical imaging, autonomous driving, robotics, and more.\n",
    "\n",
    "There are several methods for image segmentation. Here are some commonly used techniques:\n",
    "\n",
    "* **Thresholding:** This method is one of the simplest and most commonly used segmentation techniques. It involves selecting a threshold value and separating the image into two regions based on whether the pixel values are above or below the threshold.\n",
    "\n",
    "* **Edge Detection:** This method involves detecting the edges in the image and then grouping the pixels into regions based on the edges.\n",
    "\n",
    "* **Region Growing:** This method starts with a seed point and grows regions around it based on the similarity of neighboring pixels.\n",
    "\n",
    "* **Clustering:** This method groups pixels into clusters based on their similarity in color, texture, or other features.\n",
    "\n",
    "* **Watershed Segmentation:** This method treats the image as a topographic map, with the brightness of the pixels representing the elevation. It then identifies the catchment basins of the map to create segments.\n",
    "\n",
    "* **Contour-based Segmentation:** This method involves finding contours in the image and then using these contours to partition the image.\n",
    "\n",
    "* **Deep Learning-based Segmentation:** This method uses deep neural networks to learn the features of the image and segment it based on these features. This approach has become increasingly popular due to its high accuracy and ability to handle complex images."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b42bd93",
   "metadata": {
    "id": "5b42bd93"
   },
   "source": [
    "## 1. Threshold-based segmentation\n",
    "\n",
    "Threshold-based segmentation is a widely used technique in image processing and computer vision to extract objects or regions of interest from an image. There are several methods for threshold-based segmentation, including:\n",
    "\n",
    "1. Global Thresholding\n",
    "2. Adaptive Thresholding\n",
    "3. Otsu's Method\n",
    "4. Multi-level Thresholding\n",
    "5. Hysteresis Thresholding"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da59fa93",
   "metadata": {
    "id": "da59fa93"
   },
   "source": [
    "### 1.1. Global Thresholding\n",
    "\n",
    "In this method, a single threshold value is used to separate the foreground from the background. The value of the threshold is chosen based on the intensity distribution of the image, such as the mean or median intensity value of the image. If a pixel's intensity value is greater than the threshold, it is considered part of the object of interest, and if it is less than the threshold, it is considered part of the background. The different Global Thresholding Techniques are: \n",
    "\n",
    "* `cv2.THRESH_BINARY`: If pixel intensity is greater than the set threshold, value set to 255, else set to 0 (black).\n",
    "\n",
    "* `cv2.THRESH_BINARY_INV`: Inverted or Opposite case of `cv2.THRESH_BINARY`.\n",
    "\n",
    "* `cv.THRESH_TRUNC`: If pixel intensity value is greater than threshold, it is truncated to the threshold. The pixel values are set to be the same as the threshold. All other values remain the same.\n",
    "\n",
    "* `cv.THRESH_TOZERO`: Pixel intensity is set to 0, for all the pixels intensity, less than the threshold value.\n",
    "\n",
    "* `cv.THRESH_TOZERO_INV`: Inverted or Opposite case of `cv2.THRESH_TOZERO`.\n",
    "\n",
    "![Global%20based%20thresholding.png](attachment:Global%20based%20thresholding.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb75f198",
   "metadata": {
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1679643506657,
     "user": {
      "displayName": "SHUBHAM JOSHI 22923001",
      "userId": "12910899476634144541"
     },
     "user_tz": -330
    },
    "id": "fb75f198"
   },
   "outputs": [],
   "source": [
    "import cv2 \n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31ec0898",
   "metadata": {
    "executionInfo": {
     "elapsed": 628,
     "status": "ok",
     "timestamp": 1679643517211,
     "user": {
      "displayName": "SHUBHAM JOSHI 22923001",
      "userId": "12910899476634144541"
     },
     "user_tz": -330
    },
    "id": "31ec0898"
   },
   "outputs": [],
   "source": [
    "# cv2.cvtColor is applied over the\n",
    "# image input with applied parameters\n",
    "# to convert the image in grayscale \n",
    "img = cv2.imread('X-Ray.jpg', cv2.IMREAD_GRAYSCALE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0404b03b",
   "metadata": {
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1679643519932,
     "user": {
      "displayName": "SHUBHAM JOSHI 22923001",
      "userId": "12910899476634144541"
     },
     "user_tz": -330
    },
    "id": "0404b03b"
   },
   "outputs": [],
   "source": [
    "# Binary Thresholding\n",
    "# techniques on the input image\n",
    "# all pixels value above 130 will \n",
    "# be set to 255\n",
    "\n",
    "ret, thresh1 = cv2.threshold(img, 130, 255, cv2.THRESH_BINARY)\n",
    "\n",
    "# Inverted or Opposite case of above binary thresholding\n",
    "\n",
    "ret, thresh2 = cv2.threshold(img, 130, 255, cv2.THRESH_BINARY_INV)\n",
    "\n",
    "# Truncated Thresholding\n",
    "# If pixel intensity value is greater than threshold,\n",
    "# it is truncated to the threshold.\n",
    "\n",
    "ret, thresh3 = cv2.threshold(img, 130, 255, cv2.THRESH_TRUNC)\n",
    "\n",
    "# Pixel intensity is set to 0,\n",
    "# for all the pixels intensity, less than the threshold value.\n",
    "\n",
    "ret, thresh4 = cv2.threshold(img, 130, 255, cv2.THRESH_TOZERO)\n",
    "\n",
    "# Inverted or Opposite case of above (Pixel intensity is set to 0)\n",
    "\n",
    "ret, thresh5 = cv2.threshold(img, 130, 255, cv2.THRESH_TOZERO_INV)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95525e77",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51d941df",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 408
    },
    "executionInfo": {
     "elapsed": 5,
     "status": "error",
     "timestamp": 1679643548686,
     "user": {
      "displayName": "SHUBHAM JOSHI 22923001",
      "userId": "12910899476634144541"
     },
     "user_tz": -330
    },
    "id": "51d941df",
    "outputId": "b605ff82-4858-4265-f95a-cd42d621356d"
   },
   "outputs": [],
   "source": [
    "# the window showing output images\n",
    "# with the corresponding thresholding \n",
    "# techniques applied to the input images\n",
    "cv2.imshow('Original Image', img)\n",
    "cv2.imshow('Binary Threshold', thresh1)\n",
    "cv2.imshow('Binary Threshold Inverted', thresh2)\n",
    "cv2.imshow('Truncated Threshold', thresh3)\n",
    "cv2.imshow('Set to 0', thresh4)\n",
    "cv2.imshow('Set to 0 Inverted', thresh5)\n",
    "    \n",
    "# De-allocate any associated memory usage  \n",
    "if cv2.waitKey(0) & 0xff == 27: \n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15516d10",
   "metadata": {
    "id": "15516d10"
   },
   "source": [
    "### 1.2. Adaptive Thresholding\n",
    "In this method, the threshold value is computed locally for each pixel, rather than using a single global threshold for the entire image. The local threshold is based on the statistical properties of the pixel's neighborhood, which can be a fixed size or adaptive size. Adaptive thresholding is useful for images with varying illumination conditions, as it can account for local variations in brightness and contrast.\n",
    "\n",
    "We first load the image in grayscale using the `cv2.imread` function with the `cv2.IMREAD_GRAYSCALE` flag. Then, we apply the adaptive thresholding operation using the `cv2.adaptiveThreshold` function, which takes the input image, maximum pixel value (255 in this case), the adaptive thresholding method (`cv2.ADAPTIVE_THRESH_MEAN_C` in this case), the thresholding method (`cv2.THRESH_BINARY_INV` in this case), the block size (11 in this case), and the constant subtracted from the mean (2 in this case).\n",
    "\n",
    "The adaptive thresholding method calculates a threshold value for each pixel based on the mean value of the surrounding pixels in a block of a specified size. This is useful when the lighting conditions in the image vary across different regions.\n",
    "\n",
    "Finally, we show the original and thresholded images side by side using the `cv2.imshow` function, and wait for a keypress before closing the windows with `cv2.waitKey(0)` and `cv2.destroyAllWindows()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6a3a2912",
   "metadata": {
    "id": "6a3a2912"
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "# Load the image in grayscale\n",
    "img = cv2.imread('X-Ray.jpg', cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "# Apply the adaptive thresholding operation\n",
    "thresh = cv2.adaptiveThreshold(img, 255, cv2.ADAPTIVE_THRESH_MEAN_C, cv2.THRESH_BINARY_INV, 11, 2)\n",
    "\n",
    "# Show the original and thresholded images side by side\n",
    "cv2.imshow('Original', img)\n",
    "cv2.imshow('Thresholded', thresh)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6becee2",
   "metadata": {
    "id": "b6becee2"
   },
   "source": [
    "### 1.3. Otsu's Method\n",
    "This method automatically calculates the threshold by maximizing the between-class variance of the image. The algorithm assumes that the image contains two classes of pixels (foreground and background) and iteratively calculates the threshold that minimizes the within-class variance and maximizes the between-class variance.\n",
    "\n",
    "We first load the image in grayscale using the PIL library and convert it to a numpy array using `np.array`. Then, we calculate the histogram of pixel intensities using `np.histogram`, and the probability and cumulative distribution of pixel intensities using `np.cumsum`. We also calculate the mean intensity of the image.\n",
    "\n",
    "Next, we iterate over all possible threshold values from 0 to 255, and for each threshold value, we calculate the class probabilities, mean intensities, and between-class variance using the formulas for Otsu's method. We update the maximum variance and threshold values as we iterate over the threshold values.\n",
    "\n",
    "Finally, we apply the optimal threshold to the image by comparing each pixel intensity to the threshold and setting it to either 0 or 255, and then show the original and thresholded images side by side using the PIL `Image.fromarray` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ccd0d0a",
   "metadata": {
    "id": "7ccd0d0a"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from PIL import Image\n",
    "\n",
    "# Load the image in grayscale using PIL\n",
    "img = Image.open('X-Ray.jpg').convert('L')\n",
    "img_arr = np.array(img)\n",
    "\n",
    "# Calculate the histogram of pixel intensities\n",
    "hist, _ = np.histogram(img_arr, bins=256, range=(0, 255))\n",
    "\n",
    "# Calculate the probability distribution of pixel intensities\n",
    "prob = hist / np.sum(hist)\n",
    "\n",
    "# Calculate the cumulative distribution of pixel intensities\n",
    "cumsum = np.cumsum(prob)\n",
    "\n",
    "# Calculate the mean intensity of the image\n",
    "mean = np.arange(0, 256) * prob\n",
    "mean = np.sum(mean)\n",
    "\n",
    "# Initialize the maximum variance and threshold values\n",
    "max_var = 0\n",
    "threshold = 0\n",
    "\n",
    "# Iterate over all possible threshold values\n",
    "for t in range(256):\n",
    "    # Calculate the class probabilities for the two classes split by the threshold\n",
    "    w1 = cumsum[t]\n",
    "    w2 = 1 - w1\n",
    "    \n",
    "    # Skip if either class has zero probability\n",
    "    if w1 == 0 or w2 == 0:\n",
    "        continue\n",
    "    \n",
    "    # Calculate the mean intensities for the two classes split by the threshold\n",
    "    mean1 = np.sum(np.arange(0, t) * prob[:t]) / w1\n",
    "    mean2 = np.sum(np.arange(t, 256) * prob[t:]) / w2\n",
    "    \n",
    "    # Calculate the between-class variance\n",
    "    var = w1 * w2 * (mean1 - mean2) ** 2\n",
    "    \n",
    "    # Update the maximum variance and threshold values\n",
    "    if var > max_var:\n",
    "        max_var = var\n",
    "        threshold = t\n",
    "\n",
    "# Apply the threshold to the image\n",
    "thresh_img = (img_arr >= threshold) * 255\n",
    "\n",
    "# Show the original and thresholded images side by side\n",
    "Image.fromarray(img_arr).show()\n",
    "Image.fromarray(thresh_img).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96228874",
   "metadata": {
    "id": "96228874"
   },
   "source": [
    "### 1.4. Multi-level Thresholding\n",
    "\n",
    "This method is used for images with multiple objects or regions of interest that have different intensity levels. Multi-level thresholding uses multiple thresholds to segment the image into multiple classes, each corresponding to a different object or region.\n",
    "\n",
    "We first load the image in grayscale using the cv2.imread function with the `cv2.IMREAD_GRAYSCALE` flag. Then, we apply the multi-level thresholding operation using the `cv2.threshold` function, which takes the input image, a threshold value of 0, a maximum pixel value of 255, and a combination of thresholding methods (`cv2.THRESH_BINARY` and `cv2.THRESH_OTSU` in this case).\n",
    "\n",
    "The `cv2.THRESH_OTSU` method calculates the optimal threshold value using Otsu's method, which is a widely used algorithm for automatic thresholding. The `cv2.THRESH_BINARY` method converts all pixels with intensities below the threshold value to black (0) and all pixels with intensities above the threshold value to white (255).\n",
    "\n",
    "Finally, we show the original and thresholded images side by side using the `cv2.imshow function`, and wait for a keypress before closing the windows with `cv2.waitKey(0)` and `cv2.destroyAllWindows()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bda73ae",
   "metadata": {
    "id": "8bda73ae"
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "# Load the image in grayscale\n",
    "img = cv2.imread('X-Ray.jpg', cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "# Apply the multi-level thresholding operation\n",
    "_, thresh = cv2.threshold(img, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n",
    "\n",
    "# Show the original and thresholded images side by side\n",
    "cv2.imshow('Original', img)\n",
    "cv2.imshow('Thresholded', thresh)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee80634a",
   "metadata": {
    "id": "ee80634a"
   },
   "source": [
    "### 1.5. Hysteresis Thresholding\n",
    "\n",
    "This method is commonly used for edge detection in images. It involves setting two thresholds, a high threshold and a low threshold. Any pixel with an intensity value greater than the high threshold is considered part of an edge, and any pixel with an intensity value less than the low threshold is considered part of the background. Pixels with intensity values between the high and low thresholds are only considered part of the edge if they are connected to a pixel that has already been identified as part of the edge. This ensures that only continuous edges are detected.\n",
    "\n",
    "We first load the image in grayscale using the `cv2.imread` function with the `cv2.IMREAD_GRAYSCALE` flag. Then, we choose the low and high threshold values of 50 and 150, respectively. We apply the Canny edge detection algorithm using the `cv2.Canny` function, which takes the input image, low threshold value, and high threshold value as parameters.\n",
    "\n",
    "Next, we convert the edges image to an unsigned 8-bit integer using the `np.uint8` function. We apply the adaptive thresholding operation using the `cv2.adaptiveThreshold` function, which takes the edges image, maximum pixel value (255 in this case), the adaptive thresholding method (`cv2.ADAPTIVE_THRESH_MEAN_C` in this case), the thresholding method (`cv2.THRESH_BINARY_INV` in this case), the block size (3 in this case), and the constant subtracted from the mean (0 in this case).\n",
    "\n",
    "Finally, we show the original and thresholded images side by side using the `cv2.imshow` function, and wait for a keypress before closing the windows with `cv2.waitKey(0)` and `cv2.destroyAllWindows()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cce5a7c",
   "metadata": {
    "id": "1cce5a7c"
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# Load the image in grayscale\n",
    "img = cv2.imread('X-Ray.jpg', cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "# Choose the high and low threshold values\n",
    "low_thresh = 0\n",
    "high_thresh = 100\n",
    "\n",
    "# Apply the canny edge detection algorithm\n",
    "edges = cv2.Canny(img, low_thresh, high_thresh)\n",
    "\n",
    "# Apply the hysteresis thresholding operation\n",
    "edges = np.uint8(edges)\n",
    "thresh = cv2.adaptiveThreshold(edges, 255, cv2.ADAPTIVE_THRESH_MEAN_C, cv2.THRESH_BINARY_INV, 3, 0)\n",
    "\n",
    "# Show the original and thresholded images side by side\n",
    "cv2.imshow('Original', img)\n",
    "cv2.imshow('Thresholded', thresh)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eacb8abc",
   "metadata": {
    "id": "eacb8abc"
   },
   "source": [
    "## 2. Edge-based Segmentation\n",
    "Edge-based segmentation is a technique used to separate the foreground from the background in an image based on the edges present in the image. Here are some methods for edge-based segmentation:\n",
    "\n",
    "* Sobel operator\n",
    "* Canny edge detector\n",
    "* Laplacian of Gaussian (LoG) filter\n",
    "* Zero-crossing detector\n",
    "* Edge linking\n",
    "* Active contours\n",
    "* Edge-based region merging"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8cfa83d",
   "metadata": {
    "id": "a8cfa83d"
   },
   "source": [
    "### 2.1. Sobel operator\n",
    "Sobel operator is a widely used edge detection filter that computes the gradient of an image at each pixel. The gradient is a measure of how rapidly the image intensity changes in the vicinity of a pixel. By thresholding the gradient magnitude image, edges can be extracted.\n",
    "\n",
    "In this code, we use the `scipy.signal.convolve2d()` function to apply the Sobel operators to the image. We then calculate the gradient magnitude and angle using the `numpy.sqrt()` and `numpy.arctan2()` functions, respectively. Finally, we threshold the gradient magnitude to obtain a binary edge map and save it as an image using the `PIL.Image.fromarray()` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f0c7d86",
   "metadata": {
    "id": "2f0c7d86"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from PIL import Image\n",
    "from scipy.signal import convolve2d\n",
    "\n",
    "# Load the image\n",
    "img = Image.open('X-Ray.jpg').convert('L')\n",
    "\n",
    "# Convert the image to a numpy array\n",
    "img_arr = np.array(img, dtype=np.float32)\n",
    "\n",
    "# Define Sobel operator kernels\n",
    "sobel_x = np.array([[-1, 0, 1], [-2, 0, 2], [-1, 0, 1]])\n",
    "sobel_y = np.array([[-1, -2, -1], [0, 0, 0], [1, 2, 1]])\n",
    "\n",
    "# Convolve the image with the Sobel kernels to get the x and y gradients\n",
    "grad_x = convolve2d(img_arr, sobel_x, mode='same', boundary='symm')\n",
    "grad_y = convolve2d(img_arr, sobel_y, mode='same', boundary='symm')\n",
    "\n",
    "# Compute the gradient magnitude and direction\n",
    "grad_mag = np.sqrt(grad_x**2 + grad_y**2)\n",
    "grad_dir = np.arctan2(grad_y, grad_x)\n",
    "\n",
    "# Apply a threshold to get the binary edge map\n",
    "thresh = 50\n",
    "edge_map = np.zeros_like(grad_mag)\n",
    "edge_map[grad_mag > thresh] = 255\n",
    "\n",
    "# Save the edge map as an image\n",
    "edge_img = Image.fromarray(edge_map.astype(np.uint8))\n",
    "edge_img.save('X-Ray_sobel_edge_map.jpg')\n",
    "\n",
    "# Show the original and filtered images side by side\n",
    "Image.fromarray(img_arr).show()\n",
    "Image.fromarray(edge_map).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7e243d8",
   "metadata": {
    "id": "a7e243d8"
   },
   "source": [
    "### 2.2. Canny edge detector\n",
    "Canny edge detector is a popular algorithm for edge detection that involves several steps, including smoothing the image with a Gaussian filter, computing the gradient magnitude and orientation, non-maximum suppression, and hysteresis thresholding. The Canny edge detector is known for its excellent performance in detecting edges with low noise and high accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "954b98fa",
   "metadata": {
    "id": "954b98fa"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy import ndimage\n",
    "from scipy.ndimage import gaussian_filter\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae85f885",
   "metadata": {
    "id": "ae85f885"
   },
   "source": [
    "#### Step 1: Noise Reduction\n",
    "\n",
    "In this code, we use the `scipy.ndimage.gaussian_filter()` function to apply the Gaussian kernel to the image. Before that, we generate the Gaussian kernel using a nested loop that calculates the value of each pixel in the kernel based on its distance from the center and the standard deviation. We then normalize the kernel so that its sum is equal to one. Finally, we apply the Gaussian kernel to the image using the `gaussian_filter()` function and save the filtered image as a JPEG file using the `PIL.Image.fromarray()` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74426a17",
   "metadata": {
    "id": "74426a17"
   },
   "outputs": [],
   "source": [
    "# Noise Reduction\n",
    "\n",
    "# Load the image\n",
    "img = np.array(Image.open('cat.jpg'))\n",
    "img_arr = np.array(img)\n",
    "\n",
    "# Define the standard deviation of the Gaussian kernel\n",
    "sigma = 1.0\n",
    "\n",
    "# Calculate the size of the kernel based on the standard deviation\n",
    "ksize = int(4 * sigma + 1)\n",
    "\n",
    "# Generate the Gaussian kernel\n",
    "kernel = np.zeros((ksize, ksize))\n",
    "for i in range(ksize):\n",
    "    for j in range(ksize):\n",
    "        kernel[i, j] = np.exp(-((i-ksize//2)**2 + (j-ksize//2)**2) / (2*sigma**2))\n",
    "kernel /= np.sum(kernel)\n",
    "\n",
    "# Apply the Gaussian kernel to the image\n",
    "gaussian_img = gaussian_filter(img, sigma=sigma)\n",
    "\n",
    "# Save the Gaussian filtered image\n",
    "Image.fromarray(gaussian_img.astype(np.uint8)).save('cat_gaussian_img.jpg')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55f4ad2a",
   "metadata": {
    "id": "55f4ad2a"
   },
   "source": [
    "#### Step 2: Gradient Calculation\n",
    "In this code, we use the `scipy.ndimage.filters.convolve()` function to apply the Sobel filter to the image in the x and y directions, which results in the gradient components `grad_x` and `grad_y`, respectively. We then calculate the gradient magnitude and angle using the `numpy.hypot()` and `numpy.arctan2()` functions, respectively. Finally, we save the gradient magnitude as an image using the `PIL.Image.fromarray()` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c7ce894",
   "metadata": {
    "id": "9c7ce894"
   },
   "outputs": [],
   "source": [
    "\n",
    "# Load the image in grayscale\n",
    "img = np.array(Image.open('cat_gaussian_img.jpg').convert('L'))\n",
    "\n",
    "Kx = np.array([[-1, 0, 1], [-2, 0, 2], [-1, 0, 1]], np.float32)\n",
    "Ky = np.array([[1, 2, 1], [0, 0, 0], [-1, -2, -1]], np.float32)\n",
    "\n",
    "# Apply the Sobel filter to the image to obtain the x and y gradient components\n",
    "grad_x = ndimage.filters.convolve(img, Kx)\n",
    "grad_y = ndimage.filters.convolve(img, Ky)\n",
    "\n",
    "# Calculate the gradient magnitude and angle\n",
    "grad_mag = np.hypot(grad_x, grad_y)\n",
    "grad_mag = grad_mag / grad_mag.max() * 255\n",
    "grad_angle = np.arctan2(grad_y, grad_x)\n",
    "\n",
    "# Save the gradient magnitude as an image\n",
    "Image.fromarray(grad_mag.astype(np.uint8)).save('cat_sobel_img.jpg')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf20c8c0",
   "metadata": {
    "id": "cf20c8c0"
   },
   "source": [
    "#### Step 3: Non-maximum suppression\n",
    "\n",
    "In this code, we load the gradient magnitude and angle images, and define the threshold for edge detection and the size of the window for non-maximum suppression. We then pad the magnitude image with zeros to handle the borders, and create an empty array for the edge map. We loop over each pixel in the image and check if its gradient magnitude is above the threshold. If so, we determine the direction of the gradient, and determine the indices of the pixels in the direction of the gradient. We then compare the gradient magnitude of the current pixel with those of the pixels in the direction of the gradient, and add it to the edge map if it is greater than or equal to both. Finally, we save the edge map as an image using the `PIL.Image.fromarray()` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "146df646",
   "metadata": {
    "id": "146df646"
   },
   "outputs": [],
   "source": [
    "# Perform non-maximum suppression\n",
    "\n",
    "# Define the threshold for edge detection\n",
    "threshold = 80\n",
    "\n",
    "# Define the size of the window for non-maximum suppression\n",
    "window_size = 3\n",
    "\n",
    "# Pad the magnitude and angle images with zeros to handle the borders\n",
    "grad_mag_padded = np.pad(grad_mag, ((1,1),(1,1)), mode='edge')\n",
    "\n",
    "# Create an empty array for the edge map\n",
    "edge_map = np.zeros_like(grad_mag)\n",
    "\n",
    "# Perform non-maximum suppression\n",
    "for i in range(1, grad_mag.shape[0]+1):\n",
    "    for j in range(1, grad_mag.shape[1]+1):\n",
    "        # Check if the gradient magnitude is above the threshold\n",
    "        if grad_mag[i-1, j-1] > threshold:\n",
    "            # Calculate the direction of the gradient\n",
    "            angle = grad_angle[i-1, j-1]\n",
    "            if angle < 0:\n",
    "                angle += np.pi\n",
    "            angle = np.rad2deg(angle)\n",
    "            # Determine the indices of the pixels in the direction of the gradient\n",
    "            if (angle >= 0 and angle <= 22.5) or (angle > 157.5 and angle <= 180):\n",
    "                idx1, idx2 = (i, j-1), (i, j+1)\n",
    "            elif (angle > 22.5 and angle <= 67.5) or (angle > 112.5 and angle <= 157.5):\n",
    "                idx1, idx2 = (i-1, j+1), (i+1, j-1)\n",
    "            elif (angle > 67.5 and angle <= 112.5):\n",
    "                idx1, idx2 = (i-1, j), (i+1, j)\n",
    "            # Compare the gradient magnitude of the current pixel with those of the pixels in the direction of the gradient\n",
    "            if grad_mag[i-1, j-1] >= grad_mag_padded[idx1] and grad_mag[i-1, j-1] >= grad_mag_padded[idx2]:\n",
    "                edge_map[i-1, j-1] = grad_mag[i-1, j-1]\n",
    "\n",
    "# Save the edge map as an image\n",
    "Image.fromarray(edge_map.astype(np.uint8)).save('cat_edge_map.jpg')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b82fdbb0",
   "metadata": {
    "id": "b82fdbb0"
   },
   "source": [
    "#### Step 4: Double threshold\n",
    "\n",
    "In this code, we load the edge map, and define the upper and lower thresholds for double thresholding. We then apply double thresholding by creating two binary arrays: one for the strong edges above the upper threshold, and one for the weak edges between the lower and upper thresholds. We set the corresponding pixel values in the final edge map to 255 and 128, respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94f44cf1",
   "metadata": {
    "id": "94f44cf1"
   },
   "outputs": [],
   "source": [
    "# Load the edge map\n",
    "edge_map = np.array(Image.open('cat_edge_map.jpg').convert('L'))\n",
    "\n",
    "# Define the upper and lower thresholds\n",
    "upper_thresh = 150\n",
    "lower_thresh = 100\n",
    "\n",
    "# Apply double thresholding\n",
    "strong_edges = (edge_map >= upper_thresh)\n",
    "weak_edges = (edge_map >= lower_thresh) & (edge_map < upper_thresh)\n",
    "edge_map_final = np.zeros_like(edge_map)\n",
    "edge_map_final[strong_edges] = 255\n",
    "edge_map_final[weak_edges] = 128"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16d22ee5",
   "metadata": {
    "id": "16d22ee5"
   },
   "source": [
    "#### Step 5 Perform hysteresis thresholding\n",
    "We then perform hysteresis thresholding by iterating over each weak edge pixel and checking if any of its 8-connected neighbors are strong edges. If so, we set the pixel value to 255; otherwise, we set it to 0. Finally, we save the final edge map as an image using the `PIL.Image.fromarray()` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ad02f3a",
   "metadata": {
    "id": "9ad02f3a"
   },
   "outputs": [],
   "source": [
    "# Perform hysteresis thresholding\n",
    "for i in range(1, edge_map_final.shape[0]-1):\n",
    "    for j in range(1, edge_map_final.shape[1]-1):\n",
    "        if edge_map_final[i, j] == 128:\n",
    "            if (edge_map_final[i-1:i+2, j-1:j+2] == 255).any():\n",
    "                edge_map_final[i, j] = 255\n",
    "            else:\n",
    "                edge_map_final[i, j] = 0\n",
    "\n",
    "                \n",
    "# Show the original and filtered images side by side\n",
    "Image.fromarray(img_arr).show()\n",
    "Image.fromarray(edge_map_final).show()\n",
    "\n",
    "# Save the final edge map as an image\n",
    "Image.fromarray(edge_map_final.astype(np.uint8)).save('cat_edge_map_final.jpg')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e53e9d5b",
   "metadata": {
    "id": "e53e9d5b"
   },
   "source": [
    "### 2.3. Laplacian of Gaussian (LoG) filter\n",
    "LoG filter is a Gaussian filter followed by a Laplacian operator. It is used for detecting edges and features at different scales. By adjusting the standard deviation of the Gaussian filter, different scales of edges can be detected."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bbbcb11",
   "metadata": {
    "id": "1bbbcb11"
   },
   "source": [
    "In this example, we first load the image in grayscale using the PIL library and convert it to a numpy array using `np.array`. Then, we define the size of the LoG filter kernel and the standard deviation.\n",
    "\n",
    "Next, we define the LoG filter kernel using np.meshgrid to create a 2D grid of x and y values, and then calculate the values of the kernel using the formula for the LoG filter.\n",
    "\n",
    "Finally, we apply the LoG filter to the image using the `convolve` function from the `scipy.ndimage` library. This function performs convolution on two arrays and returns the result. We then show the original and filtered images side by side using the PIL `Image.fromarray` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "850799d4",
   "metadata": {
    "id": "850799d4"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy import ndimage\n",
    "from PIL import Image\n",
    "\n",
    "# Load the image in grayscale using PIL\n",
    "img = Image.open('cat.jpg').convert('L') #X-Ray imag also\n",
    "img_arr = np.array(img)\n",
    "\n",
    "# Define the size of the LoG filter kernel and the standard deviation\n",
    "ksize = 5\n",
    "sigma = 1\n",
    "\n",
    "# Define the LoG filter kernel\n",
    "x, y = np.meshgrid(np.linspace(-ksize // 2, ksize // 2, ksize),\n",
    "                   np.linspace(-ksize // 2, ksize // 2, ksize))\n",
    "kernel = (-1/(np.pi*sigma**4)) * (1 - ((x**2 + y**2)/(2*sigma**2))) * np.exp(-(x**2 + y**2)/(2*sigma**2))\n",
    "\n",
    "# Apply the LoG filter to the image using the convolve function from scipy.ndimage\n",
    "filtered_img = ndimage.convolve(img_arr, kernel)\n",
    "\n",
    "# Show the original and filtered images side by side\n",
    "Image.fromarray(img_arr).show()\n",
    "Image.fromarray(filtered_img).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a05f098",
   "metadata": {
    "id": "7a05f098"
   },
   "source": [
    "## 3. Contour-based Segmentation\n",
    "\n",
    "Contour-based segmentation is a technique used in image processing and computer vision to extract objects or regions of interest from an image based on the contours or boundaries of those objects.\n",
    "\n",
    "Contours are the outlines or boundaries of objects in an image. They can be defined as the curves that join continuous points along the boundary of an object with the same color or intensity. By using the information provided by these contours, it is possible to identify and segment objects in an image.\n",
    "\n",
    "The contour-based segmentation process involves detecting and extracting contours in the image using techniques such as edge detection, thresholding, or gradient-based methods. Once the contours are detected, they can be further processed to extract features such as area, perimeter, orientation, and shape of the objects. These features can be used to classify the objects and perform tasks such as object recognition, tracking, and counting.\n",
    "\n",
    "Contour-based segmentation is a widely used technique in various applications such as medical image analysis, surveillance, robotics, and automation.\n",
    "\n",
    "We first load an input image using the `cv2.imread()` function. Then, we convert the image to grayscale using the `cv2.cvtColor()` function. We apply binary thresholding to the grayscale image using the `cv2.threshold()` function. Next, we find the contours in the thresholded image using the `cv2.findContours()` function. Finally, we draw the contours on the original image using the `cv2.drawContours()` function and display the result using the `cv2.imshow()` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d9796b3",
   "metadata": {
    "id": "0d9796b3"
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "# Load the image\n",
    "img = cv2.imread('MRI.jpg')\n",
    "\n",
    "# Convert the image to grayscale\n",
    "gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "# Apply binary thresholding\n",
    "ret, thresh = cv2.threshold(gray, 127, 255, cv2.THRESH_BINARY)\n",
    "\n",
    "# Find the contours in the image\n",
    "contours, hierarchy = cv2.findContours(thresh, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "# Draw the contours on the original image\n",
    "cv2.drawContours(img, contours, -1, (0, 0, 255), 2)\n",
    "\n",
    "# Display the result\n",
    "cv2.imshow('contour-based segmentation', img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a298136",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
