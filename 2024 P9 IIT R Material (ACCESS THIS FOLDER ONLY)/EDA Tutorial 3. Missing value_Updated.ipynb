{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "13180532",
   "metadata": {},
   "source": [
    "# 6.4. Imputation of missing values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3524416e",
   "metadata": {},
   "source": [
    "For various reasons, many real world datasets contain missing values, often encoded as blanks, NaNs or other placeholders. Such datasets however are incompatible with scikit-learn estimators which assume that all values in an array are numerical, and that all have and hold meaning. A basic strategy to use incomplete datasets is to discard entire rows and/or columns containing missing values. However, this comes at the price of losing data which may be valuable (even though incomplete). A better strategy is to impute the missing values, i.e., to infer them from the known part of the data. See the Glossary of Common Terms and API Elements entry on imputation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4295bf9",
   "metadata": {},
   "source": [
    "# 6.4.1. Univariate vs. Multivariate Imputation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f70eee01",
   "metadata": {},
   "source": [
    "One type of imputation algorithm is univariate, which imputes values in the i-th feature dimension using only non-missing values in that feature dimension (e.g. impute.SimpleImputer). By contrast, multivariate imputation algorithms use the entire set of available feature dimensions to estimate the missing values (e.g. impute.IterativeImputer)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad526470",
   "metadata": {},
   "source": [
    "# 6.4.2. Univariate feature imputation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9386abc",
   "metadata": {},
   "source": [
    "The SimpleImputer class provides basic strategies for imputing missing values. Missing values can be imputed with a provided constant value, or using the statistics (mean, median or most frequent) of each column in which the missing values are located. This class also allows for different missing values encodings.\n",
    "\n",
    "The following snippet demonstrates how to replace missing values, encoded as np.nan, using the mean value of the columns (axis 0) that contain the missing values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "24db0bfc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[4.         2.        ]\n",
      " [6.         3.66666667]\n",
      " [7.         6.        ]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.impute import SimpleImputer\n",
    "imp = SimpleImputer(missing_values=np.nan, strategy='mean')\n",
    "imp.fit([[1, 2], [np.nan, 3], [7, 6]])\n",
    "\n",
    "X = [[np.nan, 2], [6, np.nan], [7, 6]]\n",
    "print(imp.transform(X))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "899b8137",
   "metadata": {},
   "source": [
    "The SimpleImputer class also supports sparse matrices:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "22f419ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[3. 2.]\n",
      " [6. 3.]\n",
      " [7. 6.]]\n"
     ]
    }
   ],
   "source": [
    "import scipy.sparse as sp\n",
    "X = sp.csc_matrix([[1, 2], [0, -1], [8, 4]])\n",
    "imp = SimpleImputer(missing_values=-1, strategy='mean')\n",
    "imp.fit(X)\n",
    "\n",
    "X_test = sp.csc_matrix([[-1, 2], [6, -1], [7, 6]])\n",
    "print(imp.transform(X_test).toarray())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c1d5964",
   "metadata": {},
   "source": [
    "Note that this format is not meant to be used to implicitly store missing values in the matrix because it would densify it at transform time. Missing values encoded by 0 must be used with dense input.\n",
    "\n",
    "The SimpleImputer class also supports categorical data represented as string values or pandas categoricals when using the 'most_frequent' or 'constant' strategy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0f1f7d40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['a' 'x']\n",
      " ['a' 'y']\n",
      " ['a' 'y']\n",
      " ['b' 'y']]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.DataFrame([[\"a\", \"x\"],\n",
    "                   [np.nan, \"y\"],\n",
    "                   [\"a\", np.nan],\n",
    "                   [\"b\", \"y\"]], dtype=\"category\")\n",
    "\n",
    "imp = SimpleImputer(strategy=\"most_frequent\")\n",
    "print(imp.fit_transform(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d63963fe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d1164da6",
   "metadata": {},
   "source": [
    "# 6.4.3. Multivariate feature imputation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca688d4b",
   "metadata": {},
   "source": [
    "A more sophisticated approach is to use the IterativeImputer class, which models each feature with missing values as a function of other features, and uses that estimate for imputation. It does so in an iterated round-robin fashion: at each step, a feature column is designated as output y and the other feature columns are treated as inputs X. A regressor is fit on (X, y) for known y. Then, the regressor is used to predict the missing values of y. This is done for each feature in an iterative fashion, and then is repeated for max_iter imputation rounds. The results of the final imputation round are returned."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0265fea",
   "metadata": {},
   "source": [
    "**Note** This estimator is still experimental for now: default parameters or details of behaviour might change without any deprecation cycle. Resolving the following issues would help stabilize IterativeImputer: convergence criteria (#14338), default estimators (#13286), and use of random state (#15611). To use it, you need to explicitly import enable_iterative_imputer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "dd45fc11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.  2.]\n",
      " [ 6. 12.]\n",
      " [ 3.  6.]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import IterativeImputer\n",
    "imp = IterativeImputer(max_iter=10, random_state=0)\n",
    "imp.fit([[1, 2], [3, 6], [4, 8], [np.nan, 3], [7, np.nan]])\n",
    "\n",
    "X_test = [[np.nan, 2], [6, np.nan], [np.nan, 6]]\n",
    "# the model learns that the second feature is double the first\n",
    "print(np.round(imp.transform(X_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3944b67f",
   "metadata": {},
   "source": [
    "Both SimpleImputer and IterativeImputer can be used in a Pipeline as a way to build a composite estimator that supports imputation. See Imputing missing values before building an estimator."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc9e88e3",
   "metadata": {},
   "source": [
    "# 6.4.3.1. Flexibility of IterativeImputer\n",
    "There are many well-established imputation packages in the R data science ecosystem: Amelia, mi, mice, missForest, etc. missForest is popular, and turns out to be a particular instance of different sequential imputation algorithms that can all be implemented with IterativeImputer by passing in different regressors to be used for predicting missing feature values. In the case of missForest, this regressor is a Random Forest. See Imputing missing values with variants of IterativeImputer."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38db527c",
   "metadata": {},
   "source": [
    "# 6.4.3.2. Multiple vs. Single Imputation\n",
    "In the statistics community, it is common practice to perform multiple imputations, generating, for example, m separate imputations for a single feature matrix. Each of these m imputations is then put through the subsequent analysis pipeline (e.g. feature engineering, clustering, regression, classification). The m final analysis results (e.g. held-out validation errors) allow the data scientist to obtain understanding of how analytic results may differ as a consequence of the inherent uncertainty caused by the missing values. The above practice is called multiple imputation.\n",
    "\n",
    "Our implementation of IterativeImputer was inspired by the R MICE package (Multivariate Imputation by Chained Equations) 1, but differs from it by returning a single imputation instead of multiple imputations. However, IterativeImputer can also be used for multiple imputations by applying it repeatedly to the same dataset with different random seeds when sample_posterior=True.\n",
    "It is still an open problem as to how useful single vs. multiple imputation is in the context of prediction and classification when the user is not interested in measuring uncertainty due to missing values.\n",
    "\n",
    "Note that a call to the transform method of IterativeImputer is not allowed to change the number of samples. Therefore multiple imputations cannot be achieved by a single call to transform."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c44b6eb",
   "metadata": {},
   "source": [
    "# 6.4.4. References\n",
    "1\n",
    "Stef van Buuren, Karin Groothuis-Oudshoorn (2011). “mice: Multivariate Imputation by Chained Equations in R”. Journal of Statistical Software 45: 1-67.\n",
    "\n",
    "2\n",
    "Roderick J A Little and Donald B Rubin (1986). “Statistical Analysis with Missing Data”. John Wiley & Sons, Inc., New York, NY, USA."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64d1b5cc",
   "metadata": {},
   "source": [
    "# 6.4.5. Nearest neighbors imputation\n",
    "The **KNNImputer** class provides imputation for filling in missing values using the k-Nearest Neighbors approach. By default, a euclidean distance metric that supports missing values, **nan_euclidean_distances**, is used to find the nearest neighbors. Each missing feature is imputed using values from **n_neighbors** nearest neighbors that have a value for the feature. The feature of the neighbors are averaged uniformly or weighted by distance to each neighbor. If a sample has more than one feature missing, then the neighbors for that sample can be different depending on the particular feature being imputed. When the number of available neighbors is less than **n_neighbors** and there are no defined distances to the training set, the training set average for that feature is used during imputation. If there is at least one neighbor with a defined distance, the weighted or unweighted average of the remaining neighbors will be used during imputation. If a feature is always missing in training, it is removed during **transform**. For more information on the methodology, see ref. [OL2001].\n",
    "\n",
    "The following snippet demonstrates how to replace missing values, encoded as np.nan, using the mean feature value of the two nearest neighbors of samples with missing values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7b480bfb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1. , 2. , 4. ],\n",
       "       [3. , 4. , 3. ],\n",
       "       [5.5, 6. , 5. ],\n",
       "       [8. , 8. , 7. ]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.impute import KNNImputer\n",
    "nan = np.nan\n",
    "X = [[1, 2, nan], [3, 4, 3], [nan, 6, 5], [8, 8, 7]]\n",
    "imputer = KNNImputer(n_neighbors=2, weights=\"uniform\")\n",
    "imputer.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ae57b7a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "244769d5",
   "metadata": {},
   "source": [
    "# 6.4.6. Marking imputed values\n",
    "The MissingIndicator transformer is useful to transform a dataset into corresponding binary matrix indicating the presence of missing values in the dataset. This transformation is useful in conjunction with imputation. When using imputation, preserving the information about which values had been missing can be informative. Note that both the SimpleImputer and IterativeImputer have the boolean parameter add_indicator (False by default) which when set to True provides a convenient way of stacking the output of the MissingIndicator transformer with the output of the imputer.\n",
    "\n",
    "NaN is usually used as the placeholder for missing values. However, it enforces the data type to be float. The parameter missing_values allows to specify other placeholder such as integer. In the following example, we will use -1 as missing values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9f98a621",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ True,  True, False],\n",
       "       [False,  True,  True],\n",
       "       [False,  True, False]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.impute import MissingIndicator\n",
    "X = np.array([[-1, -1, 1, 3],\n",
    "              [4, -1, 0, -1],\n",
    "              [8, -1, 1, 0]])\n",
    "indicator = MissingIndicator(missing_values=-1)\n",
    "mask_missing_values_only = indicator.fit_transform(X)\n",
    "mask_missing_values_only"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac78a2ff",
   "metadata": {},
   "source": [
    "\n",
    "The features parameter is used to choose the features for which the mask is constructed. By default, it is 'missing-only' which returns the imputer mask of the features containing missing values at fit time:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "87e1b8eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 3], dtype=int64)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "indicator.features_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e667af2d",
   "metadata": {},
   "source": [
    "The features parameter can be set to 'all' to return all features whether or not they contain missing values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "84fbf983",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ True,  True, False, False],\n",
       "       [False,  True, False,  True],\n",
       "       [False,  True, False, False]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "indicator = MissingIndicator(missing_values=-1, features=\"all\")\n",
    "mask_all = indicator.fit_transform(X)\n",
    "mask_all"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb14fb21",
   "metadata": {},
   "source": [
    "When using the MissingIndicator in a Pipeline, be sure to use the FeatureUnion or ColumnTransformer to add the indicator features to the regular features. First we obtain the iris dataset, and add some missing values to it.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f1bc0bf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.impute import SimpleImputer, MissingIndicator\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import FeatureUnion, make_pipeline\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "X, y = load_iris(return_X_y=True)\n",
    "mask = np.random.randint(0, 2, size=X.shape).astype(bool)\n",
    "X[mask] = np.nan\n",
    "X_train, X_test, y_train, _ = train_test_split(X, y, test_size=100,\n",
    "                                               random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40056a6f",
   "metadata": {},
   "source": [
    "Now we create a FeatureUnion. All features will be imputed using SimpleImputer, in order to enable classifiers to work with this data. Additionally, it adds the indicator variables from MissingIndicator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2a995d59",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 8)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transformer = FeatureUnion(\n",
    "    transformer_list=[\n",
    "        ('features', SimpleImputer(strategy='mean')),\n",
    "        ('indicators', MissingIndicator())])\n",
    "transformer = transformer.fit(X_train, y_train)\n",
    "results = transformer.transform(X_test)\n",
    "results.shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b6f6482",
   "metadata": {},
   "source": [
    "Of course, we cannot use the transformer to make any predictions. We should wrap this in a Pipeline with a classifier (e.g., a DecisionTreeClassifier) to be able to make predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0105a6a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100,)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    ">>> clf = make_pipeline(transformer, DecisionTreeClassifier())\n",
    ">>> clf = clf.fit(X_train, y_train)\n",
    ">>> results = clf.predict(X_test)\n",
    ">>> results.shape\n",
    "(100,)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bc195ca",
   "metadata": {},
   "source": [
    "# Imputing missing values before building an estimator"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "265c3bd9",
   "metadata": {},
   "source": [
    "Missing values can be replaced by the mean, the median or the most frequent value using the basic SimpleImputer."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a8c9cae",
   "metadata": {},
   "source": [
    "In this example we will investigate different imputation techniques:\n",
    "\n",
    "- imputation by the constant value 0\n",
    "\n",
    "- imputation by the mean value of each feature combined with a missing-ness indicator auxiliary variable\n",
    "\n",
    "- k nearest neighbor imputation\n",
    "\n",
    "- iterative imputation\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b4f263c",
   "metadata": {},
   "source": [
    "We will use two datasets: Diabetes dataset which consists of 10 feature variables collected from diabetes patients with an aim to predict disease progression and California Housing dataset for which the target is the median house value for California districts."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37089b52",
   "metadata": {},
   "source": [
    "As neither of these datasets have missing values, we will remove some values to create new versions with artificially missing data. The performance of RandomForestRegressor on the full original dataset is then compared the performance on the altered datasets with the artificially missing values imputed using different techniques."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0d1e604",
   "metadata": {},
   "source": [
    "# Download the data and make missing values sets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c782bcb",
   "metadata": {},
   "source": [
    "First we download the two datasets. Diabetes dataset is shipped with scikit-learn. It has 442 entries, each with 10 features. California Housing dataset is much larger with 20640 entries and 8 features. It needs to be downloaded. We will only use the first 400 entries for the sake of speeding up the calculations but feel free to use the whole dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "612ac610",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "from sklearn.datasets import fetch_california_housing, load_diabetes\n",
    "\n",
    "rng = np.random.RandomState(42)\n",
    "\n",
    "X_diabetes, y_diabetes = load_diabetes(return_X_y=True)\n",
    "X_california, y_california = fetch_california_housing(return_X_y=True)\n",
    "X_california = X_california[:300]\n",
    "y_california = y_california[:300]\n",
    "X_diabetes = X_diabetes[:300]\n",
    "y_diabetes = y_diabetes[:300]\n",
    "\n",
    "\n",
    "def add_missing_values(X_full, y_full):\n",
    "    n_samples, n_features = X_full.shape\n",
    "\n",
    "    # Add missing values in 75% of the lines\n",
    "    missing_rate = 0.75\n",
    "    n_missing_samples = int(n_samples * missing_rate)\n",
    "\n",
    "    missing_samples = np.zeros(n_samples, dtype=bool)\n",
    "    missing_samples[:n_missing_samples] = True\n",
    "\n",
    "    rng.shuffle(missing_samples)\n",
    "    missing_features = rng.randint(0, n_features, n_missing_samples)\n",
    "    X_missing = X_full.copy()\n",
    "    X_missing[missing_samples, missing_features] = np.nan\n",
    "    y_missing = y_full.copy()\n",
    "\n",
    "    return X_missing, y_missing\n",
    "\n",
    "\n",
    "X_miss_california, y_miss_california = add_missing_values(X_california, y_california)\n",
    "\n",
    "X_miss_diabetes, y_miss_diabetes = add_missing_values(X_diabetes, y_diabetes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa17e65d",
   "metadata": {},
   "source": [
    "# Impute the missing data and score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bca40d5",
   "metadata": {},
   "source": [
    "Now we will write a function which will score the results on the differently imputed data. Let’s look at each imputer separately:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f81f4e35",
   "metadata": {},
   "outputs": [],
   "source": [
    "rng = np.random.RandomState(0)\n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "# To use the experimental IterativeImputer, we need to explicitly ask for it:\n",
    "from sklearn.experimental import enable_iterative_imputer  # noqa\n",
    "from sklearn.impute import IterativeImputer, KNNImputer, SimpleImputer\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "N_SPLITS = 4\n",
    "regressor = RandomForestRegressor(random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05ae7e25",
   "metadata": {},
   "source": [
    "# Missing information"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b470734",
   "metadata": {},
   "source": [
    "In addition to imputing the missing values, the imputers have an add_indicator parameter that marks the values that were missing, which might carry some information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "047daf21",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_scores_for_imputer(imputer, X_missing, y_missing):\n",
    "    estimator = make_pipeline(imputer, regressor)\n",
    "    impute_scores = cross_val_score(\n",
    "        estimator, X_missing, y_missing, scoring=\"neg_mean_squared_error\", cv=N_SPLITS\n",
    "    )\n",
    "    return impute_scores\n",
    "\n",
    "\n",
    "x_labels = []\n",
    "\n",
    "mses_california = np.zeros(5)\n",
    "stds_california = np.zeros(5)\n",
    "mses_diabetes = np.zeros(5)\n",
    "stds_diabetes = np.zeros(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f8e61f7",
   "metadata": {},
   "source": [
    "## Estimate the score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56ceb0f9",
   "metadata": {},
   "source": [
    "First, we want to estimate the score on the original data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "7af6ebd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_full_score(X_full, y_full):\n",
    "    full_scores = cross_val_score(\n",
    "        regressor, X_full, y_full, scoring=\"neg_mean_squared_error\", cv=N_SPLITS\n",
    "    )\n",
    "    return full_scores.mean(), full_scores.std()\n",
    "\n",
    "\n",
    "mses_california[0], stds_california[0] = get_full_score(X_california, y_california)\n",
    "mses_diabetes[0], stds_diabetes[0] = get_full_score(X_diabetes, y_diabetes)\n",
    "x_labels.append(\"Full data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fc718eb",
   "metadata": {},
   "source": [
    "## Replace missing values by 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7269934",
   "metadata": {},
   "source": [
    "Now we will estimate the score on the data where the missing values are replaced by 0:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "e9255ba7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_impute_zero_score(X_missing, y_missing):\n",
    "    imputer = SimpleImputer(\n",
    "        missing_values=np.nan, add_indicator=True, strategy=\"constant\", fill_value=0\n",
    "    )\n",
    "    zero_impute_scores = get_scores_for_imputer(imputer, X_missing, y_missing)\n",
    "    return zero_impute_scores.mean(), zero_impute_scores.std()\n",
    "\n",
    "\n",
    "mses_california[1], stds_california[1] = get_impute_zero_score(\n",
    "    X_miss_california, y_miss_california\n",
    ")\n",
    "mses_diabetes[1], stds_diabetes[1] = get_impute_zero_score(\n",
    "    X_miss_diabetes, y_miss_diabetes\n",
    ")\n",
    "x_labels.append(\"Zero imputation\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11b0367a",
   "metadata": {},
   "source": [
    "## kNN-imputation of the missing values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cc829fe",
   "metadata": {},
   "source": [
    "KNNImputer imputes missing values using the weighted or unweighted mean of the desired number of nearest neighbors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "6644a1e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_impute_knn_score(X_missing, y_missing):\n",
    "    imputer = KNNImputer(missing_values=np.nan, add_indicator=True)\n",
    "    knn_impute_scores = get_scores_for_imputer(imputer, X_missing, y_missing)\n",
    "    return knn_impute_scores.mean(), knn_impute_scores.std()\n",
    "\n",
    "\n",
    "mses_california[2], stds_california[2] = get_impute_knn_score(\n",
    "    X_miss_california, y_miss_california\n",
    ")\n",
    "mses_diabetes[2], stds_diabetes[2] = get_impute_knn_score(\n",
    "    X_miss_diabetes, y_miss_diabetes\n",
    ")\n",
    "x_labels.append(\"KNN Imputation\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d4360e0",
   "metadata": {},
   "source": [
    "## Impute missing values with mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "4f9fe907",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_impute_mean(X_missing, y_missing):\n",
    "    imputer = SimpleImputer(missing_values=np.nan, strategy=\"mean\", add_indicator=True)\n",
    "    mean_impute_scores = get_scores_for_imputer(imputer, X_missing, y_missing)\n",
    "    return mean_impute_scores.mean(), mean_impute_scores.std()\n",
    "\n",
    "\n",
    "mses_california[3], stds_california[3] = get_impute_mean(\n",
    "    X_miss_california, y_miss_california\n",
    ")\n",
    "mses_diabetes[3], stds_diabetes[3] = get_impute_mean(X_miss_diabetes, y_miss_diabetes)\n",
    "x_labels.append(\"Mean Imputation\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f745d25",
   "metadata": {},
   "source": [
    "## Iterative imputation of the missing values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56c232fb",
   "metadata": {},
   "source": [
    "Another option is the IterativeImputer. This uses round-robin linear regression, modeling each feature with missing values as a function of other features, in turn. The version implemented assumes Gaussian (output) variables. If your features are obviously non-normal, consider transforming them to look more normal to potentially improve performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "01ad12ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_impute_iterative(X_missing, y_missing):\n",
    "    imputer = IterativeImputer(\n",
    "        missing_values=np.nan,\n",
    "        add_indicator=True,\n",
    "        random_state=0,\n",
    "        n_nearest_features=3,\n",
    "        max_iter=1,\n",
    "        sample_posterior=True,\n",
    "    )\n",
    "    iterative_impute_scores = get_scores_for_imputer(imputer, X_missing, y_missing)\n",
    "    return iterative_impute_scores.mean(), iterative_impute_scores.std()\n",
    "\n",
    "\n",
    "mses_california[4], stds_california[4] = get_impute_iterative(\n",
    "    X_miss_california, y_miss_california\n",
    ")\n",
    "mses_diabetes[4], stds_diabetes[4] = get_impute_iterative(\n",
    "    X_miss_diabetes, y_miss_diabetes\n",
    ")\n",
    "x_labels.append(\"Iterative Imputation\")\n",
    "\n",
    "mses_diabetes = mses_diabetes * -1\n",
    "mses_california = mses_california * -1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "580ad288",
   "metadata": {},
   "source": [
    "### Plot the results\n",
    "\n",
    "Finally we are going to visualize the score:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "22710d91",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x432 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "n_bars = len(mses_diabetes)\n",
    "xval = np.arange(n_bars)\n",
    "\n",
    "colors = [\"r\", \"g\", \"b\", \"orange\", \"black\"]\n",
    "\n",
    "# plot diabetes results\n",
    "plt.figure(figsize=(12, 6))\n",
    "ax1 = plt.subplot(121)\n",
    "for j in xval:\n",
    "    ax1.barh(\n",
    "        j,\n",
    "        mses_diabetes[j],\n",
    "        xerr=stds_diabetes[j],\n",
    "        color=colors[j],\n",
    "        alpha=0.6,\n",
    "        align=\"center\",\n",
    "    )\n",
    "\n",
    "ax1.set_title(\"Imputation Techniques with Diabetes Data\")\n",
    "ax1.set_xlim(left=np.min(mses_diabetes) * 0.9, right=np.max(mses_diabetes) * 1.1)\n",
    "ax1.set_yticks(xval)\n",
    "ax1.set_xlabel(\"MSE\")\n",
    "ax1.invert_yaxis()\n",
    "ax1.set_yticklabels(x_labels)\n",
    "\n",
    "# plot california dataset results\n",
    "ax2 = plt.subplot(122)\n",
    "for j in xval:\n",
    "    ax2.barh(\n",
    "        j,\n",
    "        mses_california[j],\n",
    "        xerr=stds_california[j],\n",
    "        color=colors[j],\n",
    "        alpha=0.6,\n",
    "        align=\"center\",\n",
    "    )\n",
    "\n",
    "ax2.set_title(\"Imputation Techniques with California Data\")\n",
    "ax2.set_yticks(xval)\n",
    "ax2.set_xlabel(\"MSE\")\n",
    "ax2.invert_yaxis()\n",
    "ax2.set_yticklabels([\"\"] * n_bars)\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0067ac51",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
